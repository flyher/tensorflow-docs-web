<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
<html>
<head>
    <meta http-equiv="Content-Type" content="text/html;charset=UTF-8">
    <title>使用即时编译</title>
    <link href="//xitu.github.io/tensorflow-docs-web/assets/css/bootstrap.min.css" rel="stylesheet">
    <link href="//xitu.github.io/tensorflow-docs-web/assets/css/main.css" rel="stylesheet">
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css">
</head>
<body>
<!-- Header start -->
<nav class="navbar navbar-expand-lg navbar-light bg-light">
    <a class="navbar-brand" href="#">TensorFlow</a>
    <button class="navbar-toggler" type="button" aria-expanded="false" aria-label="Menu"
            onclick="$('.collapse').toggle()">
        <span class="navbar-toggler-icon"></span>
    </button>

    <div class="collapse navbar-collapse">
        <ul class="navbar-nav mr-auto">
        </ul>
        <!-- TODO: Search function-->
        <!--<form class="form-inline my-2 my-lg-0">-->
            <!--<input class="form-control mr-sm-2" type="search" placeholder="Search" aria-label="Search">-->
            <!--<button class="btn btn-outline-success my-2 my-sm-0" type="submit">Search</button>-->
        <!--</form>-->
    </div>
</nav>
<script>
    var head = [{'link': '//xitu.github.io/tensorflow-docs-web/extend/index.html', 'name': '扩展', 'selected': 0}, {'link': '//xitu.github.io/tensorflow-docs-web/install/index.html', 'name': '安装 TensorFlow', 'selected': 0}, {'link': '//xitu.github.io/tensorflow-docs-web/deploy/index.html', 'name': '部署', 'selected': 0}, {'link': '//xitu.github.io/tensorflow-docs-web/about/index.html', 'name': 'About TensorFlow', 'selected': 0}, {'link': '//xitu.github.io/tensorflow-docs-web/get_started/index.html', 'name': '开始', 'selected': 0}, {'link': '//xitu.github.io/tensorflow-docs-web/mobile/index.html', 'name': '概述', 'selected': 0}, {'link': '//xitu.github.io/tensorflow-docs-web/tutorials/index.html', 'name': '教程', 'selected': 0}, {'link': '//xitu.github.io/tensorflow-docs-web/javascript/index.html', 'name': 'JavaScript', 'selected': 0}, {'link': '//xitu.github.io/tensorflow-docs-web/performance/index.html', 'name': '性能', 'selected': 0}, {'link': '//xitu.github.io/tensorflow-docs-web/community/index.html', 'name': 'Community', 'selected': 0}, {'link': '//xitu.github.io/tensorflow-docs-web/programmers_guide/index.html', 'name': '开发者指南', 'selected': 0}]
</script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-92630037-8"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-92630037-8');
</script>

<!-- Header end -->

<!-- Content start-->
<div class="container-fluid">
    <div class="row">
        
        <main role="main" class="col-md-9 ml-sm-auto col-lg-10 pt-3 px-4">
            <h1>使用即时编译</h1>
<blockquote><p>注意: 为了支持 XLA（加速线性代数），TensorFlow 必须从源文件编译。</p>
</blockquote>
<h2>为什么使用即时编译？</h2>
<p>TensorFlow / XLA 即时编译器通过 XLA 编译和运行 TensorFlow 图的各个部分。与标准的 TensorFlow 实现相比，XLA 的好处是可以将多个运算符（内核融合）融合到少量的编译内核中。与 TensorFlow 逐个运行操作相比，融合运算能减少对内存带宽的要求，同时提升性能。</p>
<h2>通过 XLA 运行 TensorFlow 图</h2>
<p>有两种方式通过 XLA 运行 TensorFlow 计算图：一是用 CPU 或 GPU 设备上的即时编译操作，二是把操作放到 <code>XLA_CPU</code> 或 <code>XLA_GPU</code> TensorFlow 设备上。将操作直接放到一个 TensorFlow XLA<br>
设备上强制执行，因此这种方法主要用于测试。</p>
<blockquote><p>注意：XLA CPU 后端会生成快速、单线程的代码，但是不会如 TensorFlow CPU 后端一样并行化。 XLA GPU 后端与标准的 TensorFlow 后端充分竞争，运行速度时快时慢。</p>
</blockquote>
<h3>开启即时编译</h3>
<p>即时编译可以在会话层开启，或手动进行选择操作。两种方式都是零拷贝 --- 数据在同台设备的已编译 XLA 内核和 TensorFlow 操作之间传递时，无需另行复制。</p>
<h4>会话</h4>
<p>在会话层开启即时编译时，系统将尽可能把所有操作编译成 XLA 计算。每个 XLA 计算将被编译成单个或多个设备底层内核。</p>
<p>受某些限制影响，如果图模型中有两个相邻的操作都要使用 XLA，它们将会被编译成单个 XLA 计算。</p>
<p>通过将 <code>global_jit_level</code> 设置成<code>tf.OptimizerOptions.ON_1</code>，并在会话初始化阶段传入配置，就可以在会话层开启即时编译。</p>
<pre><code class="lang-python"># 配置开启即时编译
config = tf.ConfigProto()
config.graph_options.optimizer_options.global_jit_level = tf.OptimizerOptions.ON_1

sess = tf.Session(config=config)
</code></pre>
<blockquote><p>注意：在会话层开启即时编译将不会导致为 CPU 编译操作。CPU 运算的即时编译必须通过下面描述的手动方法开启，原因在于 CPU 后端是单线程的。</p>
</blockquote>
<h4>手动开启</h4>
<p>对于单个或多个操作，可以手动开启即时编译，通过对运算进行标记以使用属性 <code>_XlaCompile=true</code> 来进行编译。最简单的方法就是通过在 <a href="https://www.tensorflow.org/code/tensorflow/contrib/compiler/jit.py"><code>tensorflow/contrib/compiler/jit.py</code></a><br>
中定义的 <code>tf.contrib.compiler.jit.experimental_jit_scope()</code> 。<br>
使用范例：</p>
<pre><code class="lang-python">    jit_scope = tf.contrib.compiler.jit.experimental_jit_scope

    x = tf.placeholder(np.float32)
    with jit_scope():
      y = tf.add(x, x)  # add 将被 XLA 编译
</code></pre>
<p><code>_XlaCompile</code> 属性目前是以最佳的方式支持的。如果一个操作无法编译，TensorFlow 将默认回退到常规实现。</p>
<h3>将操作加载到 XLA 设备中</h3>
<p>通过 XLA 执行计算的另一种方法是将操作载入到特定的 XLA 设备上。这个方法通常只用于测试。有效设备包括 <code>XLA_CPU</code> 或 <code>XLA_GPU</code>。</p>
<pre><code class="lang-python">with tf.device(&quot;/job:localhost/replica:0/task:0/device:XLA_GPU:0&quot;):
  output = tf.add(input1, input2)
</code></pre>
<p>不同于标准 CPU 和 GPU 设备上的即时编译，这些设备在传输到设备上和关闭设备时，会生成一个数据副本。额外的拷贝导致在同一个图模型中混合使用 XLA 和 TensorFlow 操作的开销变得很大。</p>
<h2>教程</h2>
<p>这个教程涵盖了一个简单版的 MNIST softmax 训练模型。在会话层开启了即时编译，只支持 GPU。</p>
<p>在开始本教程之前，先验证 LD_LIBRARY 环境变量或者 ldconfig 包含 <code>$CUDA_ROOT/extras/CUPTI/lib64</code>，其中包含 CUDA 分析工具接口库<br>
<a href="http://docs.nvidia.com/cuda/cupti/index.html">(CUPTI)</a>。TensorFlow 使用 CUPTI 从 GPU 获取追踪信息。</p>
<h3>步骤 #1: 准备代码范例</h3>
<p>下载或移动 <a href="https://www.tensorflow.org/code/tensorflow/examples/tutorials/mnist/mnist_softmax_xla.py">mnist_softmax_xla.py</a> 到 TensorFlow 源码之外的文件夹中。</p>
<h3>步骤 #2: 无 XLA 运行</h3>
<p>执行 python 代码，不用 XLA 训练模型。</p>
<pre><code class="lang-shell">python mnist_softmax_xla.py --xla=&#39;&#39;
</code></pre>
<p>使用 Chrome 跟踪事件探查器 (导航到 chrome://tracing)，当代码执行完时打开时间线文件 <code>timeline.ctf.json</code>。呈现的时间线类似于下图，其中有多个绿色框，标记为 <code>MatMul</code>，可能跨多个 GPU 。</p>
<div style="width:95%; margin:auto; margin-bottom:10px; margin-top:20px;">
  <img style="width:100%" src="https://www.tensorflow.org/images/jit_timeline_gpu.png">
</div><h3>步骤 #3：用 XLA 运行代码</h3>
<p>执行 python 代码，用 XLA 训练模型，并打开 XLA 调试工具，用环境变量输出 XLA 图。</p>
<pre><code class="lang-shell">TF_XLA_FLAGS=--xla_generate_hlo_graph=.* python mnist_softmax_xla.py
</code></pre>
<p>打开时间线文件(<code>timeline.ctf.json</code>)。呈现的时间线类似于下图，其中有一个标有 <code>_XlaLaunch</code><br>
的长块。</p>
<div style="width:95%; margin:auto; margin-bottom:10px; margin-top:20px;">
  <img style="width:100%" src="https://www.tensorflow.org/images/jit_timeline_gpu_xla.png">
</div><p>通过查看控制台类似下面的输出来了解在 <code>_XlaLaunch</code> 里到底发生了什么:</p>
<pre><code class="lang-shell">computation cluster_0[_XlaCompiledKernel=true,_XlaNumConstantArgs=1].v82 [CPU:
pipeline start, before inline]: /tmp/hlo_graph_0.dot
</code></pre>
<p>控制台显示了包含 XLA 创建的图模型信息的 <code>hlo_graph_xx.dot</code> 文件位置。XLA 融合操作的过程可以从 <code>hlo_graph_0.dot</code> 开始逐个查看分析图了解。</p>
<p>为了将 .dot 文件渲染成 png 格式，需安装 <a href="https://www.graphviz.org/download/">GraphViz</a> 并运行:</p>
<pre><code class="lang-shell">dot -Tpng hlo_graph_80.dot -o hlo_graph_80.png
</code></pre>
<p>结果如下图：</p>
<div style="width:95%; margin:auto; margin-bottom:10px; margin-top:20px;">
  <img style="width:100%" src="https://www.tensorflow.org/images/jit_gpu_xla_graph.png">
</div>
        </main>
    </div>
</div>
<!-- Content end-->

<!-- Footer start -->
<footer class="footer">
    <div class="container">
        <div>如果您发现本页面存在错误或可以改进，请<a href="https://github.com/xitu/tensorflow-docs/blob/zh-hans/performance/xla/jit.md" target="_blank">点击此处</a>帮助我们改进。本页贡献者：<span id="contributors"></span></div>
        <hr/>
        <div class="text-center official-links">
            <a href="https://www.tensorflow.org"><img
                    src="https://www.tensorflow.org/_static/b1fb9a8564/images/tensorflow/lockup.png" height="20"/></a>
            <a href="https://github.com/xitu/tensorflow-docs"><img
                    src="https://assets-cdn.github.com/images/modules/logos_page/GitHub-Logo.png" height="20"></a>
            <a href="https://juejin.im"><img src="//xitu.github.io/tensorflow-docs-web/assets/imgs/logo_app_white.png" height="20"/></a>
        </div>
    </div>
</footer>
<script>
    var contributors = [{'徐键': ''}, {'leviding': 'https://avatars3.githubusercontent.com/u/26959437?v=4'}]
</script>
<!-- Footer end -->
</body>
<script src="//cdn.bootcss.com/jquery/3.3.1/jquery.slim.min.js" type="text/javascript"></script>
<script src="//cdn.bootcss.com/highlight.js/9.12.0/highlight.min.js" type="text/javascript"></script>
<script src="//xitu.github.io/tensorflow-docs-web/assets/js/main.js" type="text/javascript"></script>
</html>
<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
<html>
<head>
    <meta http-equiv="Content-Type" content="text/html;charset=UTF-8">
    <title>使用（多个）GPU</title>
    <link href="//tensorflow.juejin.im/assets/css/bootstrap.min.css" rel="stylesheet">
    <link href="//tensorflow.juejin.im/assets/css/main.css" rel="stylesheet">
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css">
</head>
<body>
<!-- Header start -->
<nav class="navbar navbar-expand-lg navbar-light bg-light">
    <a class="navbar-brand" href="//tensorflow.juejin.im">TensorFlow</a>
    <button class="navbar-toggler" type="button" aria-expanded="false" aria-label="Menu"
            onclick="$('.collapse').toggle()">
        <span class="navbar-toggler-icon"></span>
    </button>

    <div class="collapse navbar-collapse">
        <ul class="navbar-nav mr-auto">
        </ul>
        <!-- TODO: Search function-->
        <!--<form class="form-inline my-2 my-lg-0">-->
            <!--<input class="form-control mr-sm-2" type="search" placeholder="Search" aria-label="Search">-->
            <!--<button class="btn btn-outline-success my-2 my-sm-0" type="submit">Search</button>-->
        <!--</form>-->
    </div>
</nav>
<script>
    var head = [{'link': '//tensorflow.juejin.im/extend/index.html', 'name': '扩展', 'selected': 0}, {'link': '//tensorflow.juejin.im/install/index.html', 'name': '安装 TensorFlow', 'selected': 0}, {'link': '//tensorflow.juejin.im/deploy/index.html', 'name': '部署', 'selected': 0}, {'link': '//tensorflow.juejin.im/about/index.html', 'name': '关于 TensorFlow', 'selected': 0}, {'link': '//tensorflow.juejin.im/get_started/index.html', 'name': '开始', 'selected': 0}, {'link': '//tensorflow.juejin.im/mobile/index.html', 'name': '概述', 'selected': 0}, {'link': '//tensorflow.juejin.im/tutorials/index.html', 'name': '教程', 'selected': 0}, {'link': '//tensorflow.juejin.im/javascript/index.html', 'name': 'JavaScript', 'selected': 0}, {'link': '//tensorflow.juejin.im/performance/index.html', 'name': '性能', 'selected': 0}, {'link': '//tensorflow.juejin.im/community/index.html', 'name': '社区', 'selected': 0}, {'link': '//tensorflow.juejin.im/programmers_guide/index.html', 'name': '开发者指南', 'selected': 1}]
</script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-92630037-8"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-92630037-8');
</script>

<!-- Header end -->

<!-- Content start-->
<div class="container-fluid">
    <div class="row">
        <nav class="col-md-2 d-none d-md-block bg-light sidebar">
    <div class="sidebar-sticky" id="left-nav">

    </div>
</nav>
<script>
    var nav = [{'type': 'child', 'link': '//tensorflow.juejin.im/programmers_guide/index.html', 'title': '开发者指南'}, {'type': 'parent', 'title': ' High Level APIs', 'sub_class': [{'link': '//tensorflow.juejin.im/programmers_guide/eager.html', 'title': 'Eager Execution'}, {'link': '//tensorflow.juejin.im/programmers_guide/datasets.html', 'title': '数据导入'}, {'link': '//tensorflow.juejin.im/programmers_guide/estimators.html', 'title': '评估器'}]}, {'type': 'parent', 'title': ' Low Level APIs', 'sub_class': [{'link': '//tensorflow.juejin.im/programmers_guide/low_level_intro.html', 'title': '底层 API 编程介绍'}, {'link': '//tensorflow.juejin.im/programmers_guide/tensors.html', 'title': '张量'}, {'link': '//tensorflow.juejin.im/programmers_guide/variables.html', 'title': '变量'}, {'link': '//tensorflow.juejin.im/programmers_guide/graphs.html', 'title': '流图与会话'}, {'link': '//tensorflow.juejin.im/programmers_guide/saved_model.html', 'title': '保存和恢复'}]}, {'type': 'parent', 'title': ' Accelerators', 'sub_class': [{'link': '//tensorflow.juejin.im/programmers_guide/using_gpu.html', 'title': '使用（多个）GPU'}, {'link': '//tensorflow.juejin.im/programmers_guide/using_tpu.html', 'title': '使用 TPU'}]}, {'type': 'parent', 'title': ' ML Concepts', 'sub_class': [{'link': '//tensorflow.juejin.im/programmers_guide/embedding.html', 'title': 'Embeddings'}]}, {'type': 'parent', 'title': ' Debugging', 'sub_class': [{'link': '//tensorflow.juejin.im/programmers_guide/debugger.html', 'title': 'TensorFlow 调试器'}]}, {'type': 'parent', 'title': ' TensorBoard', 'sub_class': [{'link': '//tensorflow.juejin.im/programmers_guide/summaries_and_tensorboard.html', 'title': 'Tensorboard：可视化学习面板'}, {'link': '//tensorflow.juejin.im/programmers_guide/graph_viz.html', 'title': 'TensorBoard: 图形可视化'}, {'link': '//tensorflow.juejin.im/programmers_guide/tensorboard_histograms.html', 'title': 'TensorBoard 直方图面板'}]}, {'type': 'parent', 'title': ' Misc', 'sub_class': [{'link': '//tensorflow.juejin.im/programmers_guide/version_compat.html', 'title': 'TensorFlow 版本兼容性'}, {'link': '//tensorflow.juejin.im/programmers_guide/faq.html', 'title': '常见问题'}]}]
</script>
        <main role="main" class="col-12 col-md-9 col-xl-8 py-md-3 pl-md-5 bd-content">
            <h1 id="toc-0">使用（多个）GPU</h1>
<h2 id="toc-1">支持的设备</h2>
<p>在一个典型的系统上，有多个计算设备。在 TensorFlow 中，支持的设备类型是“CPU”和“GPU”。 它们都是字符串形式。<br>
例如：</p>
<ul>
<li>  <code>"/cpu:0"</code>：你的机器上的 CPU。</li>
<li>  <code>"/device:GPU:0"</code>：你的机器上的 GPU（如果有的话）。</li>
<li>  <code>"/device:GPU:1"</code>：你的机器上的第二块 GPU ，以此类推。</li>
</ul>
<p>如果某个 TensorFlow 的操作同时有 CPU 和 GPU 的实现，当它被分配给设备（以执行）时，GPU 将被优先考虑。 例如，<code>matmul</code> 有 CPU 和 GPU 的内核实现，在同时具备“cpu：0”和“gpu：0“设备的系统上，将选择“gpu：0”来执行“matmul”。</p>
<h2 id="toc-2">设备配置信息日志记录</h2>
<p>为了解你的操作和张量被分配给了哪些设备，请创建 session ，并将 log_device_placement 配置选项置为 True。</p>
<pre><code class="lang-python"># 创建一个 graph。
a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name=&#39;a&#39;)
b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name=&#39;b&#39;)
c = tf.matmul(a, b)
# 创建一个 session ，并将 log_device_placement 设置为 True。
sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))
# 执行这个操作。
print(sess.run(c))
</code></pre>
<p>将会看到以下输出:</p>
<pre><code>Device mapping:
/job:localhost/replica:0/task:0/device:GPU:0 -&gt; device: 0, name: Tesla K40c, pci bus
id: 0000:05:00.0
b: /job:localhost/replica:0/task:0/device:GPU:0
a: /job:localhost/replica:0/task:0/device:GPU:0
MatMul: /job:localhost/replica:0/task:0/device:GPU:0
[[ 22.  28.]
 [ 49.  64.]]
</code></pre>
<h2 id="toc-3">手动分配设备</h2>
<p>如果你希望某个特定操作在你选择的设备上运行，而非自动选择，可以使用 <code>tf.device</code> 创建设备的上下文，如此一来，该上下文内部的所有操作都将使用你所指定的设备运行。</p>
<pre><code class="lang-python"># 创建一个 graph。
with tf.device(&#39;/cpu:0&#39;):
  a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name=&#39;a&#39;)
  b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name=&#39;b&#39;)
c = tf.matmul(a, b)
# 创建一个 session ，并将 log_device_placement 设置为 True。
sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))
# 执行这个操作。
print(sess.run(c))
</code></pre>
<p>可以看到 <code>a</code> 和 <code>b</code> 当前被分配给了 <code>cpu:0</code>。由于 <code>Matmul</code> 操作没有被指定设备，TensorFlow 运行时会基于当前操作和可用设备进行选择，还会在设备间自动复制张量（如果要求的话）。</p>
<pre><code>Device mapping:
/job:localhost/replica:0/task:0/device:GPU:0 -&gt; device: 0, name: Tesla K40c, pci bus
id: 0000:05:00.0
b: /job:localhost/replica:0/task:0/cpu:0
a: /job:localhost/replica:0/task:0/cpu:0
MatMul: /job:localhost/replica:0/task:0/device:GPU:0
[[ 22.  28.]
 [ 49.  64.]]
</code></pre>
<h2 id="toc-4">允许 GPU 显存增长</h2>
<p>默认情况下，Tensorflow 会使用所有 GPU 上的几乎所有的显存（取决于系统环境变量 <a href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#env-vars"><code>CUDA_VISIBLE_DEVICES</code></a>）去运行程序。这样做是为了通过减少<a href="https://en.wikipedia.org/wiki/Fragmentation_\(computing\">内存碎片</a>)来更有效利用设备上相对宝贵的GPU显存资源。</p>
<p>在某些情况下，进程仅分配一部分可用显存或视进程需要再行增加显存使用量这种做法是可取的。TensorFlow 在 Session 上提供了两个 Config 选项来设置。</p>
<p>第一个选项是 <code>allow_growth</code>，尝试仅分配尽可能多的支持运行的 GPU 显存：它一开始分配很少的内存，当 Sessions 运行并需要更多的 GPU 显存时，拓展 Tensorflow 程序所需要的 GPU 显存区域。注意，我们不会释放显存，因为这会导致更加严重的内存碎片问题。可以在 ConfigProto 打开这个选项：</p>
<pre><code class="lang-python">config = tf.ConfigProto()
config.gpu_options.allow_growth = True
session = tf.Session(config=config, ...)
</code></pre>
<p>第二个选项是 <code>pre_process_gpu_memory_fraction</code>，它决定了每个可见的 GPU 应该被分配多大比例的显存。例如，对于每个 GPU，你想让 TensorFlow 仅仅分配总显存的 40%，就这么做：</p>
<pre><code class="lang-python">config = tf.ConfigProto()
config.gpu_options.per_process_gpu_memory_fraction = 0.4
session = tf.Session(config=config, ...)
</code></pre>
<p>如果您想真正限制可用于 TensorFlow 进程的 GPU 显存用量，这是非常有用的。</p>
<h2 id="toc-5">在一个多 GPU 机器上使用单个 GPU</h2>
<p>如果你的机器上有不止一个 GPU ，Tensorflow 将默认使用 ID 编号最小的那个。如果你想在别的 GPU 上运行，你需要明确指定 GPU 的 ID：</p>
<pre><code class="lang-python"># 创建一个 graph。
with tf.device(&#39;/device:GPU:2&#39;):
  a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name=&#39;a&#39;)
  b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name=&#39;b&#39;)
  c = tf.matmul(a, b)
# 创建一个 session ，并将 log_device_placement 设置为 True。
sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))
# 执行这个操作。
print(sess.run(c))
</code></pre>
<p>如果你指定的设备不存在，你会得到一个错误 ：<code>InvalidArgumentError</code> 。</p>
<pre><code>InvalidArgumentError: Invalid argument: Cannot assign a device to node 'b':
Could not satisfy explicit device specification '/device:GPU:2'
   [[Node: b = Const[dtype=DT_FLOAT, value=Tensor&lt;type: float shape: [3,2]
   values: 1 2 3...&gt;, _device="/device:GPU:2"]()]]
</code></pre>
<p>如果你想让 Tensorflow 自动选择现有且受支持的设备来运行操作，以防指定的设备不存在，你可以在创建 session 时在配置选项中将 <code>allow_soft_placement</code> 设置为 <code>True</code>。</p>
<pre><code class="lang-python"># 创建一个 graph。
with tf.device(&#39;/device:GPU:2&#39;):
  a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name=&#39;a&#39;)
  b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name=&#39;b&#39;)
  c = tf.matmul(a, b)
# Creates a session with allow_soft_placement and log_device_placement set
# 创建一个 session ，并将 allow_soft_placement 和 log_device_placement 设置为 True。
sess = tf.Session(config=tf.ConfigProto(
      allow_soft_placement=True, log_device_placement=True))
# 执行这个操作。
print(sess.run(c))
</code></pre>
<h2 id="toc-6">使用多个 GPU</h2>
<p>如果你想在多个 GPU 上运行 Tensorflow ，可以采用 multi-tower 的方式构建模型，其中每个 tower 分配给不同的 GPU 。<br>
例如：</p>
<pre><code class="lang-python"># 创建一个 graph。
c = []
for d in [&#39;/device:GPU:2&#39;, &#39;/device:GPU:3&#39;]:
  with tf.device(d):
    a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3])
    b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2])
    c.append(tf.matmul(a, b))
with tf.device(&#39;/cpu:0&#39;):
  sum = tf.add_n(c)
# 创建一个 session ，并将 log_device_placement 设置为 True。
sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))
# 执行这个操作。
print(sess.run(sum))
</code></pre>
<p>将会看到以下输出：</p>
<pre><code>Device mapping:
/job:localhost/replica:0/task:0/device:GPU:0 -&gt; device: 0, name: Tesla K20m, pci bus
id: 0000:02:00.0
/job:localhost/replica:0/task:0/device:GPU:1 -&gt; device: 1, name: Tesla K20m, pci bus
id: 0000:03:00.0
/job:localhost/replica:0/task:0/device:GPU:2 -&gt; device: 2, name: Tesla K20m, pci bus
id: 0000:83:00.0
/job:localhost/replica:0/task:0/device:GPU:3 -&gt; device: 3, name: Tesla K20m, pci bus
id: 0000:84:00.0
Const_3: /job:localhost/replica:0/task:0/device:GPU:3
Const_2: /job:localhost/replica:0/task:0/device:GPU:3
MatMul_1: /job:localhost/replica:0/task:0/device:GPU:3
Const_1: /job:localhost/replica:0/task:0/device:GPU:2
Const: /job:localhost/replica:0/task:0/device:GPU:2
MatMul: /job:localhost/replica:0/task:0/device:GPU:2
AddN: /job:localhost/replica:0/task:0/cpu:0
[[  44.   56.]
 [  98.  128.]]
</code></pre>
<p><a href="//tensorflow.juejin.im/tutorials/deep_cnn.html">卷积神经网络</a></p>

        </main>
        <div class="d-none d-xl-block col-xl-2 bd-toc">
        <ul id="table-of-content">
<li><a href="#toc-0">使用（多个）GPU</a><ul>
<li><a href="#toc-1">支持的设备</a></li>
<li><a href="#toc-2">设备配置信息日志记录</a></li>
<li><a href="#toc-3">手动分配设备</a></li>
<li><a href="#toc-4">允许 GPU 显存增长</a></li>
<li><a href="#toc-5">在一个多 GPU 机器上使用单个 GPU</a></li>
<li><a href="#toc-6">使用多个 GPU</a></li>
</ul>
</li>
</ul>

        </div>
    </div>
</div>
<!-- Content end-->

<!-- Footer start -->
<footer class="footer">
    <div class="container">
        <div>如果您发现本页面存在错误或可以改进，请<a href="https://github.com/xitu/tensorflow-docs/blob/zh-hans/programmers_guide/using_gpu.md" target="_blank">点击此处</a>帮助我们改进。本页贡献者：<span id="contributors"></span></div>
        <hr/>
        <div class="text-center official-links">
            <a href="https://www.tensorflow.org"><img
                    src="https://www.tensorflow.org/_static/b1fb9a8564/images/tensorflow/lockup.png" height="20"/></a>
            <a href="https://github.com/xitu/tensorflow-docs"><img
                    src="https://assets-cdn.github.com/images/modules/logos_page/GitHub-Logo.png" height="20"></a>
            <a href="https://juejin.im"><img src="//tensorflow.juejin.im/assets/imgs/logo_app_white.png" height="20"/></a>
        </div>
    </div>
</footer>
<script>
    var contributors = [{'leviding': 'https://avatars3.githubusercontent.com/u/26959437?v=4'}]
</script>
<!-- Footer end -->
</body>
<script src="//cdn.bootcss.com/jquery/3.3.1/jquery.slim.min.js" type="text/javascript"></script>
<script src="//cdn.bootcss.com/highlight.js/9.12.0/highlight.min.js" type="text/javascript"></script>
<script src="//tensorflow.juejin.im/assets/js/main.js" type="text/javascript"></script>
</html>
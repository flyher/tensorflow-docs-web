<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
<html>
<head>
    <meta http-equiv="Content-Type" content="text/html;charset=UTF-8">
    <title>添加一个新操作（Op）</title>
    <link href="//xitu.github.io/tensorflow-docs-web/assets/css/bootstrap.min.css" rel="stylesheet">
    <link href="//xitu.github.io/tensorflow-docs-web/assets/css/main.css" rel="stylesheet">
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css">
</head>
<body>
<!-- Header start -->
<nav class="navbar navbar-expand-lg navbar-light bg-light">
    <a class="navbar-brand" href="#">TensorFlow</a>
    <button class="navbar-toggler" type="button" aria-expanded="false" aria-label="Menu"
            onclick="$('.collapse').toggle()">
        <span class="navbar-toggler-icon"></span>
    </button>

    <div class="collapse navbar-collapse">
        <ul class="navbar-nav mr-auto">
        </ul>
        <!-- TODO: Search function-->
        <!--<form class="form-inline my-2 my-lg-0">-->
            <!--<input class="form-control mr-sm-2" type="search" placeholder="Search" aria-label="Search">-->
            <!--<button class="btn btn-outline-success my-2 my-sm-0" type="submit">Search</button>-->
        <!--</form>-->
    </div>
</nav>
<script>
    var head = [{'link': '//xitu.github.io/tensorflow-docs-web/extend/index.html', 'name': '扩展', 'selected': 1}, {'link': '//xitu.github.io/tensorflow-docs-web/install/index.html', 'name': '安装 TensorFlow', 'selected': 0}, {'link': '//xitu.github.io/tensorflow-docs-web/deploy/index.html', 'name': '部署', 'selected': 0}, {'link': '//xitu.github.io/tensorflow-docs-web/about/index.html', 'name': 'About TensorFlow', 'selected': 0}, {'link': '//xitu.github.io/tensorflow-docs-web/get_started/index.html', 'name': '开始', 'selected': 0}, {'link': '//xitu.github.io/tensorflow-docs-web/mobile/index.html', 'name': '概述', 'selected': 0}, {'link': '//xitu.github.io/tensorflow-docs-web/tutorials/index.html', 'name': '教程', 'selected': 0}, {'link': '//xitu.github.io/tensorflow-docs-web/javascript/index.html', 'name': 'JavaScript', 'selected': 0}, {'link': '//xitu.github.io/tensorflow-docs-web/performance/index.html', 'name': '性能', 'selected': 0}, {'link': '//xitu.github.io/tensorflow-docs-web/community/index.html', 'name': 'Community', 'selected': 0}, {'link': '//xitu.github.io/tensorflow-docs-web/programmers_guide/index.html', 'name': '开发者指南', 'selected': 0}]
</script>
<!-- Header end -->

<!-- Content start-->
<div class="container-fluid">
    <div class="row">
        <nav class="col-md-2 d-none d-md-block bg-light sidebar">
    <div class="sidebar-sticky" id="left-nav">

    </div>
</nav>
<script>
    var nav = [{'type': 'child', 'link': '//xitu.github.io/tensorflow-docs-web/extend/index.html', 'title': '扩展'}, {'type': 'child', 'link': '//xitu.github.io/tensorflow-docs-web/extend/architecture.html', 'title': 'TensorFlow 架构'}, {'type': 'child', 'link': '//xitu.github.io/tensorflow-docs-web/extend/adding_an_op.html', 'title': '添加一个新操作（Op）'}, {'type': 'child', 'link': '//xitu.github.io/tensorflow-docs-web/extend/add_filesys.html', 'title': '添加一个定制的文件系统插件'}, {'type': 'child', 'link': '//xitu.github.io/tensorflow-docs-web/extend/new_data_formats.html', 'title': '读取自定义文件和记录格式'}, {'type': 'child', 'link': '//xitu.github.io/tensorflow-docs-web/extend/language_bindings.html', 'title': '在其他语言中绑定 TensorFlow'}, {'type': 'child', 'link': '//xitu.github.io/tensorflow-docs-web/extend/tool_developers/index.html', 'title': '工具开发者指南：TensorFlow 模型文件'}]
</script>
        <main role="main" class="col-md-9 ml-sm-auto col-lg-10 pt-3 px-4">
            <h1>添加一个新操作（Op）</h1>
<p>注意：默认情况下 <a href="https://tensorflow.org">www.tensorflow.org</a> 显示最新稳定版本的文档。<br>
本文档中的说明需要从源代码构建。你很可能想要从 TensorFlow 的 <code>master</code> 版本开始构建。<br>
那么，你就应该遵循<a href="https://www.tensorflow.org/versions/master/extend/adding_an_op">本文档的 <code>master</code> 版本</a><br>
，以防发生任何更改。</p>
<p>如果你想要创建一个在已有 TensorFlow 库中不存在的操作，我们建议你先从 Python 入手，即写一个已有 Python 操作或函数的复合操作。<br>
如果这样不可行，你可以定制一个 C++ 操作。下面是你可能需要这样做的一些理由：</p>
<ul>
<li>  将你的操作表示成现有操作的组合不太容易或不可能。</li>
<li>  已有基本操作的组合操作效率不高。</li>
<li>  你想手工实现一些基本操作的组合，因为未来的编译器做这种融合可能会比较困难。</li>
</ul>
<p>例如，想象一下，你想实现类似于“最大值池化（MaxPool）”的“中值池化”操作，只不过不再是计算最大值，而是在滑动窗口上计算中值。<br>
这种操作是可能通过操作组合实现的，比如使用 ExtractImagePatches 和 TopK，但是这可能在性能上、或内存开销上不如原生操作，<br>
因为你可以在单一的融合操作中采用一些高明的策略。大体上，首先尝试用组合操作来实现你的想法总是值得一试的，只有当组合操作很困难或低效时才考虑添加一个新的操作。</p>
<p>为了加入一个定制操作，你需要：</p>
<ol>
<li>在 C++ 文件中注册这个新操作。操作的注册为此操作的功能定义了一个接口（规范）。比如，操作的注册定义了此操作的名称和它的输入输出。它还定义了 shape 函数，用于获取张量的形状。</li>
<li>在 C++ 中实现这个操作。操作的实现称为内核，它是你在步骤 1 中注册的规范的具体实现。对于不同的输入输出类型或架构（比如不同的 CPUs 或 GPUs），可能有多个内核。</li>
<li>创建一个 Python 包装器（可选）。这个包装器是用于在 Python 中创建操作的公共 API。操作的注册可以产生一个默认的包装器，它可以直接使用，或添加。</li>
<li>为操作编写一个函数来计算梯度（可选）。</li>
<li><a href="https://www.tensorflow.org/api_docs/python/tf/test/compute_gradient_error"><code>tf.test.compute_gradient_error</code></a></li>
</ol>
<p>编写新操作代码前，你需要：</p>
<ul>
<li>  熟悉 C++ 。</li>
<li><a href="//xitu.github.io/tensorflow-docs-web/install/install_sources.html">通过源码安装 TensorFlow</a></li>
</ul>
<p>[TOC]</p>
<h2>定义操作接口</h2>
<p>操作接口的定义是通过在 TensorFlow 系统中注册来实现的。在此注册过程中，需要指定操作名称、输入（类型和名称）和输出（类型和名称），以及文档字符串和此操作要求的任何<a href="#属性">属性</a>。</p>
<p>下面展示注册的具体过程。假设你想创建一个操作，其输入是一个 <code>int32</code> 类型的张量，而输出是此张量的一个副本，副本除第一个元素设为零之外其它都不变。为此，创建一个名为 <code>zero_out.cc</code> 的文件。然后调用<br>
<code>REGISTER_OP</code> 宏，以定义你的操作：</p>
<pre><code class="lang-c++">#include &quot;tensorflow/core/framework/op.h&quot;
#include &quot;tensorflow/core/framework/shape_inference.h&quot;

using namespace tensorflow;

REGISTER_OP(&quot;ZeroOut&quot;)
    .Input(&quot;to_zero: int32&quot;)
    .Output(&quot;zeroed: int32&quot;)
    .SetShapeFn([](::tensorflow::shape_inference::InferenceContext* c) {
      c-&gt;set_output(0, c-&gt;input(0));
      return Status::OK();
    });
</code></pre>
<p>于是，我们注册了一个名为 <code>ZeroOut</code> 的操作，它的输入（命名为 <code>to_zero</code>）和输出（命名为 <code>zeroed</code>）都是 32 位整数类型的张量。此操作利用一个 shape 函数来确保输出张量与输入张量保持一致。比如，如果输入张量为 [10, 20]，则此 shape 函数将输出张量也指定为 [10, 20]。</p>
<blockquote><p>  关于命名的备注：操作名称必须首字母大写，而且不能和库中已经注册的其它操作重名。</p>
</blockquote>
<h2>实现操作的内核</h2>
<p>定义接口后，接下来就需要为此操作提供一个或多个内核实现了。<br>
为了实现这些内核，创建一个继承自 <code>OpKernel</code> 的类，并重载 <code>Compute</code> 方法。<br>
<code>Compute</code> 方法有一个类型为 <code>OpKernelContext*</code> 的参数 <code>context</code>，从中可以访问输入和输出张量等有用的信息。</p>
<p>将你的内核加到上面创建的文件中。这个内核的代码形如：</p>
<pre><code class="lang-c++">#include &quot;tensorflow/core/framework/op_kernel.h&quot;

using namespace tensorflow;

class ZeroOutOp : public OpKernel {
 public:
  explicit ZeroOutOp(OpKernelConstruction* context) : OpKernel(context) {}

  void Compute(OpKernelContext* context) override {
    // 得到输入张量
    const Tensor&amp; input_tensor = context-&gt;input(0);
    auto input = input_tensor.flat&lt;int32&gt;();

    // 创建输出张量
    Tensor* output_tensor = NULL;
    OP_REQUIRES_OK(context, context-&gt;allocate_output(0, input_tensor.shape(),
                                                     &amp;output_tensor));
    auto output_flat = output_tensor-&gt;flat&lt;int32&gt;();

    // 除第一个元素外，输出张量的其它所有元素都设置为 0 
    const int N = input.size();
    for (int i = 1; i &lt; N; i++) {
      output_flat(i) = 0;
    }

    // 如果可能的话，保留第一个输入值
    if (N &gt; 0) output_flat(0) = input(0);
  }
};
</code></pre>
<p>实现完内核之后，将其注册到 TensorFlow 系统中。在注册中，你还要指定此内核运行时的不同约束条件。比如，你可能有一个内核是针对 CPU 的，而还有一个是针对 GPU 的。</p>
<p>为了给 <code>ZeroOut</code> 操作加上约束条件，将下面的代码加到 <code>zero_out.cc</code> 文件中：</p>
<pre><code class="lang-c++">REGISTER_KERNEL_BUILDER(Name(&quot;ZeroOut&quot;).Device(DEVICE_CPU), ZeroOutOp);
</code></pre>
<blockquote><p>重要提示：你的 OpKernel 实例有可能会被并发访问，所以 <code>Compute</code> 方法必须是线程安全的。可以用线程互斥锁来保护类成员的每一次访问。更好的办法是，不要通过类成员来共享状态！可以考虑使用一个 <a href="https://www.tensorflow.org/code/tensorflow/core/framework/resource_mgr.h"><code>ResourceMgr</code></a>来跟踪操作的状态。</p>
</blockquote>
<h3>多线程 CPU 内核</h3>
<p>为了编写一个多线程 CPU 内核，可使用<br>
<a href="https://www.tensorflow.org/code/tensorflow/core/util/work_sharder.h"><code>work_sharder.h</code></a><br>
中的 Shard 函数。在 intra-op 线程模式下，此函数将计算函数分片到各个线程执行（参见<br>
<a href="https://www.tensorflow.org/code/tensorflow/core/protobuf/config.proto"><code>config.proto</code></a> 中定义的 intra_op_parallelism_threads  模式）。</p>
<h3>GPU 内核</h3>
<p>一个 GPU 内核的实现包括两个部分：OpKernel 子类、CUDA 内核及其启动代码。</p>
<p>有时候 OpKernel 实现可由 CPU 和 GPU 内核共享，这一部分代码可以完成诸如检查输入和分配输出之类的任务。<br>
如果采用这种方案，则我们建议用如下实现方式：</p>
<ol>
<li>在设备上定义模板化的 OpKernel，并定义张量的基本类型</li>
<li>为了完成输出的实际计算， Compute 函数要调用一个模板化的函子结构</li>
<li>此函子针对 CPU 设备（CPUDevice）的特性化可在同一个文件中定义，但针对 GPU 设备（GPUDevice）的特性化要单独定义在一个 .cu.cc 文件中，因为它需要用 CUDA 编译器来编译。</li>
</ol>
<p>下面是一个实现的示例：</p>
<pre><code class="lang-c++">// kernel_example.h
#ifndef KERNEL_EXAMPLE_H_
#define KERNEL_EXAMPLE_H_

template &lt;typename Device, typename T&gt;
struct ExampleFunctor {
  void operator()(const Device&amp; d, int size, const T* in, T* out);
};

#if GOOGLE_CUDA
// Partially specialize functor for GpuDevice.
template &lt;typename Eigen::GpuDevice, typename T&gt;
struct ExampleFunctor {
  void operator()(const Eigen::GpuDevice&amp; d, int size, const T* in, T* out);
};
#endif

#endif KERNEL_EXAMPLE_H_
</code></pre>
<pre><code class="lang-c++">// kernel_example.cc
#include &quot;example.h&quot;
#include &quot;tensorflow/core/framework/op_kernel.h&quot;

using namespace tensorflow;

using CPUDevice = Eigen::ThreadPoolDevice;
using GPUDevice = Eigen::GpuDevice;

// 实际计算的 CPU 模板特性化
template &lt;typename T&gt;
struct ExampleFunctor&lt;CPUDevice, T&gt; {
  void operator()(const CPUDevice&amp; d, int size, const T* in, T* out) {
    for (int i = 0; i &lt; size; ++i) {
      out[i] = 2 * in[i];
    }
  }
};

// OpKernel 子类的定义
// 模板参数 &lt;T&gt; 为张量的数据类型
template &lt;typename Device, typename T&gt;
class ExampleOp : public OpKernel {
 public:
  explicit ExampleOp(OpKernelConstruction* context) : OpKernel(context) {}

  void Compute(OpKernelContext* context) override {
    // 获得输入张量
    const Tensor&amp; input_tensor = context-&gt;input(0);

    // 创建输出张量
    Tensor* output_tensor = NULL;
    OP_REQUIRES_OK(context, context-&gt;allocate_output(0, input_tensor.shape(),
                                                     &amp;output_tensor));

    // 执行计算
    OP_REQUIRES(context, input_tensor.NumElements() &lt;= tensorflow::kint32max,
                errors::InvalidArgument(&quot;Too many elements in tensor&quot;));
    ExampleFunctor&lt;Device, T&gt;()(
        context-&gt;eigen_device&lt;Device&gt;(),
        static_cast&lt;int&gt;(input_tensor.NumElements()),
        input_tensor.flat&lt;T&gt;().data(),
        output_tensor-&gt;flat&lt;T&gt;().data());
  }
};

// 注册 CPU 内核
#define REGISTER_CPU(T)                                          \
  REGISTER_KERNEL_BUILDER(                                       \
      Name(&quot;Example&quot;).Device(DEVICE_CPU).TypeConstraint&lt;T&gt;(&quot;T&quot;), \
      ExampleOp&lt;CPUDevice, T&gt;);
REGISTER_CPU(float);
REGISTER_CPU(int32);

// 注册 GPU 内核
#ifdef GOOGLE_CUDA
#define REGISTER_GPU(T)                                          \
  /* 在 kernel_example.cu.cc 中显式声明模板实例化 */ \
  extern template ExampleFunctor&lt;GPUDevice, float&gt;;              \
  REGISTER_KERNEL_BUILDER(                                       \
      Name(&quot;Example&quot;).Device(DEVICE_GPU).TypeConstraint&lt;T&gt;(&quot;T&quot;), \
      ExampleOp&lt;GPUDevice, T&gt;);
REGISTER_GPU(float);
REGISTER_GPU(int32);
#endif  // GOOGLE_CUDA
</code></pre>
<pre><code class="lang-c++">// kernel_example.cu.cc
#ifdef GOOGLE_CUDA
#define EIGEN_USE_GPU
#include &quot;example.h&quot;
#include &quot;tensorflow/core/util/cuda_kernel_helper.h&quot;

using namespace tensorflow;

using GPUDevice = Eigen::GpuDevice;

// 定义 CUDA 内核
template &lt;typename T&gt;
__global__ void ExampleCudaKernel(const int size, const T* in, T* out) {
  for (int i = blockIdx.x * blockDim.x + threadIdx.x; i &lt; size;
       i += blockDim.x * gridDim.x) {
    out[i] = 2 * ldg(in + i);
  }
}

// 定义启动 CUDA 内核的 GPU 实现
template &lt;typename T&gt;
void ExampleFunctor&lt;GPUDevice, T&gt;::operator()(
    const GPUDevice&amp; d, int size, const T* in, T* out) {
  // 启动 CUDA 内核
  //
  // 参见 core/util/cuda_kernel_helper.h 中的计算线程块数目和每块线程数（thread_per_block）的示例
  int block_count = 1024;
  int thread_per_block = 20;
  ExampleCudaKernel&lt;T&gt;
      &lt;&lt;&lt;block_count, thread_per_block, 0, d.stream()&gt;&gt;&gt;(size, in, out);
}

// 显式实例化函子，这些函子用于处理注册的那些 OpKernel 支持的类型
template struct ExampleFunctor&lt;GPUDevice, float&gt;;
template struct ExampleFunctor&lt;GPUDevice, int32&gt;;

#endif  // GOOGLE_CUDA
</code></pre>
<h2>构建操作的库文件</h2>
<h3>用系统编译器来编译操作（TensorFlow 二进制安装）</h3>
<p>你可以用 <code>C++</code> 编译器来编译 <code>zero_out.cc</code>，比如你的系统上的 <code>g++</code> 或 <code>clang</code> 都是可以的。用 PIP 包管理器来安装二进制 TensorFlow 时，已经包含了编译操作所需的头文件和库文件，具体的安装目录则取决于你的操作系统。<br>
不过，TensorFlow 的 python 库提供了 <code>get_include</code> 函数来获得头文件目录，也提供了 <code>get_lib</code> 函数来获得链接所需库文件的目录位置。下面是 Ubuntu 机器上这两个函数的输出结果：</p>
<pre><code class="lang-bash">$ python
&gt;&gt;&gt; import tensorflow as tf
&gt;&gt;&gt; tf.sysconfig.get_include()
&#39;/usr/local/lib/python2.7/site-packages/tensorflow/include&#39;
&gt;&gt;&gt; tf.sysconfig.get_lib()
&#39;/usr/local/lib/python2.7/site-packages/tensorflow&#39;
</code></pre>
<p>假如你的系统上安装了 <code>g++</code>，下面的命令可于将你的操作编译成一个动态库。</p>
<pre><code class="lang-bash">TF_CFLAGS=( $(python -c &#39;import tensorflow as tf; print(&quot; &quot;.join(tf.sysconfig.get_compile_flags()))&#39;) )
TF_LFLAGS=( $(python -c &#39;import tensorflow as tf; print(&quot; &quot;.join(tf.sysconfig.get_link_flags()))&#39;) )
g++ -std=c++11 -shared zero_out.cc -o zero_out.so -fPIC ${TF_CFLAGS[@]} ${TF_LFLAGS[@]} -O2
</code></pre>
<p>在 Mac OS X 上，构建 <code>.so</code> 文件时还需要额外的编译标志 "-undefined dynamic_lookup" 。</p>
<blockquote><p>  注意，如果 <code>gcc</code> 版本 <code>&gt;=5</code>，则 gcc 使用的新的 C++ <a href="https://gcc.gnu.org/gcc-5/changes.html#libstdcxx">ABI</a>。TensorFlow 官网上提供的二进制 pip 包用的是 <code>gcc4</code> 构建的，即它用的是较早的 ABI。如果你用 <code>gcc&gt;=5</code> 来编译你的操作库文件，在命令行中加入 <code>-D_GLIBCXX_USE_CXX11_ABI=0</code> 来让生成的库文件与旧的 ABI 兼容。此外，如果你使用从源码构建 TensorFlow ，记得在用 bazel 命令编译 Python 包时中加上编译选项 <code>--cxxopt="-D_GLIBCXX_USE_CXX11_ABI=0"</code>。</p>
</blockquote>
<h3>使用 bazel 编译操作（TensorFlow 源码安装）</h3>
<p>如果你安装了 TensorFlow 源码，则你可以利用 TensorFLow 的构建系统来编译你的操作。把一个 BUILD 文件放在<br>
<a href="https://www.tensorflow.org/code/tensorflow/core/user_ops/"><code>tensorflow/core/user_ops</code></a> 目录中，其中包含 Bazel 的构建规则，内容如下：</p>
<pre><code class="lang-python">load(&quot;//tensorflow:tensorflow.bzl&quot;, &quot;tf_custom_op_library&quot;)

tf_custom_op_library(
    name = &quot;zero_out.so&quot;,
    srcs = [&quot;zero_out.cc&quot;],
)
</code></pre>
<p>运行下列命令来构建 <code>zero_out.so</code>.</p>
<pre><code class="lang-bash">$ bazel build --config opt //tensorflow/core/user_ops:zero_out.so
</code></pre>
<blockquote><p>  注意：虽然你可以用标准 <code>cc_library</code> 规则来生成一个共享库文件（<code>.so</code> 文件），我们还是强烈推荐使用 <code>tf_custom_op_library</code> 宏。这个宏加了一些必要的依赖项，而且还包含一些检查，以确保输出的共享库文件与 TensorFlow 的插件加载机制兼容。</p>
</blockquote>
<h2>在 Python 中使用新的操作</h2>
<p><a href="https://www.tensorflow.org/api_docs/python/tf/load_op_library"><code>tf.load_op_library</code></a></p>
<pre><code class="lang-python">import tensorflow as tf
zero_out_module = tf.load_op_library(&#39;./zero_out.so&#39;)
with tf.Session(&#39;&#39;):
  zero_out_module.zero_out([[1, 2], [3, 4]]).eval()

# 打印
array([[1, 0], [0, 0]], dtype=int32)
</code></pre>
<p>需要注意，生成的函数采用蛇形命令规则（snake_case），这是为了遵守 <a href="https://www.python.org/dev/peps/pep-0008/">PEP8</a> 规范。<br>
所以，如果你的操作在 C++ 代码中命名为 <code>ZeroOut</code>，则它的 Python 函数名会变成 <code>zero_out</code>。</p>
<p>为了让该操作可以像常规函数一样从某个模块中导入（<code>import</code>），则可以在 Python 源码中调用 <code>load_op_library</code> 函数：</p>
<pre><code class="lang-python">import tensorflow as tf

zero_out_module = tf.load_op_library(&#39;./zero_out.so&#39;)
zero_out = zero_out_module.zero_out
</code></pre>
<h2>验证操作正常运行</h2>
<p>确认你编写的操作是否可成功运行的一个好办法是写一个测试。创建文件 <code>zero_out_op_test.py</code>，内容如下：</p>
<pre><code class="lang-python">import tensorflow as tf

class ZeroOutTest(tf.test.TestCase):
  def testZeroOut(self):
    zero_out_module = tf.load_op_library(&#39;./zero_out.so&#39;)
    with self.test_session():
      result = zero_out_module.zero_out([5, 4, 3, 2, 1])
      self.assertAllEqual(result.eval(), [5, 0, 0, 0, 0])

if __name__ == &quot;__main__&quot;:
  tf.test.main()
</code></pre>
<p>然后，运行该测试（假设你已经安装了 TensorFlow）：</p>
<pre><code class="lang-sh">$ python zero_out_op_test.py
</code></pre>
<h2>在操作中加入高级功能</h2>
<p>现在你已经知道如何实现和构建一个基本的操作（更恰当地说，是一个受限的操作），那么接下来，我们将介绍你在编写新操作时通常会用到的一些更复杂的功能，包括：</p>
<ul>
<li>  <a href="#conditional-checks-and-validation">条件检查和验证</a></li>
<li>  <a href="#op-registration">操作注册</a><ul>
<li>  <a href="#attrs">属性</a></li>
<li>  <a href="#attr-types">属性类型</a></li>
<li>  <a href="#polymorphism">多态</a></li>
<li>  <a href="#inputs-and-outputs">输入输出</a></li>
<li>  <a href="#backwards-compatibility">后向兼容</a></li>
</ul>
</li>
<li>  <a href="#gpu_support">GPU 支持</a><ul>
<li>  <a href="#compiling-the-kernel-for-the-gpu-device">为 GPU 设备编译内核</a></li>
</ul>
</li>
<li>  <a href="#implement-the-gradient-in-python">在 Python 中实现梯度计算</a></li>
<li>  <a href="#shape-functions-in-c">C++ 中的形状函数</a></li>
</ul>
<h3>条件检查和验证</h3>
<p>上述示例假定操作适用于任意形状的张量。但如果我们只处理矢量呢？那么我们就需要在 OpKernel 的实现中加入一个检查：</p>
<pre><code class="lang-c++">  void Compute(OpKernelContext* context) override {
    // 获得输入张量
    const Tensor&amp; input_tensor = context-&gt;input(0);

    OP_REQUIRES(context, TensorShapeUtils::IsVector(input_tensor.shape()),
                errors::InvalidArgument(&quot;ZeroOut expects a 1-D vector.&quot;));
    // ...
  }
</code></pre>
<p>这里我们加了一个断言，它要求输入是一个矢量，否则将设置 <code>InvalidArgument</code> 状态。<a href="https://www.tensorflow.org/code/tensorflow/core/lib/core/errors.h"><code>OP_REQUIRES</code> 宏</a> 有三个参数：</p>
<ul>
<li>  上下文 <code>context</code>：既可以是一个 <code>OpKernelContext</code>，也可以是一个 <code>OpKernelConstruction</code> 指针（参见<br>
   <a href="https://www.tensorflow.org/code/tensorflow/core/framework/op_kernel.h"><code>tensorflow/core/framework/op_kernel.h</code></a> 文件），用于其 <code>SetStatus()</code> 方法。</li>
<li>  条件：关于验证张量形状的更多函数，参见文件<br>
   <a href="https://www.tensorflow.org/code/tensorflow/core/framework/tensor_shape.h"><code>tensorflow/core/framework/tensor_shape.h</code></a></li>
<li>  错误本身：它由一个 <code>Status</code> 对象表示，参见文件<br>
   <a href="https://www.tensorflow.org/code/tensorflow/core/lib/core/status.h"><code>tensorflow/core/lib/core/status.h</code></a>。一个 <code>Status</code> 对象包含一个类型（常为 <code>InvalidArgument</code>，但能看到类型列表）和一条消息。构建一个错误的函数参见文件<br>
  <a href="https://www.tensorflow.org/code/tensorflow/core/lib/core/errors.h"><code>tensorflow/core/lib/core/errors.h</code></a>。</li>
</ul>
<p>另外，如果你想测试从某个函数返回的 <code>Status</code> 对象是否为错误，则使用宏 <a href="https://www.tensorflow.org/code/tensorflow/core/lib/core/errors.h"><code>OP_REQUIRES_OK</code></a>。这两个宏都会在错误报错时返回错误对象。</p>
<h3>操作的注册</h3>
<h4>属性</h4>
<p>操作可以有属性，当一个操作被加到计算图中时，它的属性就会被赋值。这些属性用于配置此操作，它们的值既可以在内核实现中访问，也可以在操作注册时的输入输出类型中进行访问。相较于输入，参数的使用要尽量避免，因为输入更为灵活一些。这是因为属性是常数，<br>
必须在计算图构造时定义。相反，输入作为张量，它的值是动态的；即输入的值在每一步都可以修改，比如使用 feed。属性主要用于无法使用输入的场合：任何影响特征（输入输出的数量和类型）的配置，或无法在每一步修改的时候。</p>
<p>你需要在注册操作时定义属性，定义时要指定名称和使用 <code>Attr</code> 方法的类型，此方法的参数规范如下：</p>
<pre><code>&lt;name&gt;: &lt;attr-type-expr&gt;
</code></pre>
<p>其中 <code>&lt;name&gt;</code> 以字母开头，由数字、字母和下划线组成，而 <code>&lt;attr-type-expr&gt;</code> 一个类型表达式（参见<a href="#attr_types">下方</a>）。</p>
<p>比如，如果你想让 <code>ZeroOut</code> 操作保留用户指定的索引，而不是仅保留第 0 个元素，你可以按下面的方式来注册操作：</p>
<pre class="prettyprint"><code class="lang-cpp">
REGISTER\_OP("ZeroOut")
    <b>.Attr("preserve\_index: int")</b>
    .Input("to\_zero: int32")
    .Output("zeroed: int32");
</code></pre><p><a href="https://www.tensorflow.org/api_docs/python/tf/DType"><code>tf.DType</code></a></p>
<p>你实现的内核可以在构造函数中通过 <code>context</code> 参数来访问属性：</p>
<pre class="prettyprint"><code class="lang-cpp">
class ZeroOutOp : public OpKernel {
 public:
  explicit ZeroOutOp(OpKernelConstruction\* context) : OpKernel(context) {<b>
    // 获取待保存的索引值
    OP\_REQUIRES\_OK(context,
                   context-&gt;GetAttr("preserve\_index", &preserve\_index\_));
    // 检查 preserve\_index 是否为正值
    OP\_REQUIRES(context, preserve\_index_ &gt;= 0,
                errors::InvalidArgument("Need preserve\_index &gt;= 0, got ",
                                        preserve\_index_));
  </b>}
  void Compute(OpKernelContext\* context) override {
    // ...
  }
 <b>private:
  int preserve\_index\_;</b>
};
</code></pre><p>还可以在 <code>Compute</code> 方法中使用这个参数：</p>
<pre class="prettyprint"><code class="lang-cpp">
  void Compute(OpKernelContext\* context) override {
    // ...
<br/>
    <b>// 我们用保存的属性来检查动态输入的合法性
    // 所以，我们检查 preserve\_index 是否在允许的值域范围内
    OP\_REQUIRES(context, preserve\_index_ &lt; input.dimension(0),
                errors::InvalidArgument("preserve\_index out of range"));<br/>
    </b>// 将输出张量中所有元素设置为 0
    const int N = input.size();
    for (int i = 0; i < N; i++) {
      output\_flat(i) = 0;
    }<br/>
    <b>// 保存指定位置的输入值
    output\_flat(preserve\_index\_) = input(preserve\_index\_);</b>
  }
</code></pre><h4>属性类型</h4>
<p>属性支持下列数据类型：</p>
<ul>
<li><code>string</code>：任意字节序列（不要求是 UTF8 编码）</li>
<li><code>int</code>：有符号整数</li>
<li><code>float</code>: 浮点数</li>
<li><code>bool</code>: True 或 false</li>
<li><code>type</code>： <a href="https://www.tensorflow.org/code/tensorflow/core/framework/types.cc"><code>DataType</code></a> 的其中一个（非引用）值</li>
<li><code>shape</code>：一个 <a href="https://www.tensorflow.org/code/tensorflow/core/framework/tensor_shape.proto"><code>TensorShapeProto</code></a></li>
<li><code>tensor</code>：一个 <a href="https://www.tensorflow.org/code/tensorflow/core/framework/tensor.proto"><code>TensorProto</code></a></li>
<li><code>list(&lt;type&gt;)</code>： <code>&lt;type&gt;</code> 的列表，其中 <code>&lt;type&gt;</code> 为其中一种上述类型<br>
 注意： <code>list(list(&lt;type&gt;))</code> 是非法的。</li>
</ul>
<p>欲了解限定性列表，参见 <a href="https://www.tensorflow.org/code/tensorflow/core/framework/op_def_builder.cc"><code>op_def_builder.cc:FinalizeAttr</code></a>。</p>
<h5>默认值和约束</h5>
<p>属性可以有默认值，有一些属性则还可以有约束。为了定义一个有约束的属性，可以使用下列属性类型表达式（<code>&lt;attr-type-expr&gt;</code>）：</p>
<ul>
<li><p><code>{'&lt;string1&gt;', '&lt;string2&gt;'}</code>：表示在 <code>&lt;string1&gt;</code> 或 <code>&lt;string2&gt;</code> 这两种取值中二选一。当你使用这种语法时，系统自动推断出属性类型为 <code>string</code>。这相当于模仿构造了一个枚举：</p>
<pre><code class="lang-c++">REGISTER_OP(&quot;EnumExample&quot;)
    .Attr(&quot;e: {&#39;apple&#39;, &#39;orange&#39;}&quot;);
</code></pre>
</li>
<li><p><a href="https://www.tensorflow.org/api_docs/python/tf/DType"><code>tf.DType</code></a></p>
<pre><code class="lang-c++">REGISTER_OP(&quot;RestrictedTypeExample&quot;)
    .Attr(&quot;t: {int32, float, bool}&quot;);
</code></pre>
</li>
<li><p>常用的类型约束可以有如下别名：</p>
<ul>
<li><code>numbertype</code>：<code>type</code> 类型被限制为数值类型（不是字符串，也不是布尔类型）</li>
<li><code>realnumbertype</code>：类似于 <code>numbertype</code> 类型，但不包括复数类型</li>
<li><code>quantizedtype</code>：类型于 <code>numbertype</code> 类型，但只包括量化数值类型</li>
</ul>
<p>   属性所支持的类型列表可通过 <a href="https://www.tensorflow.org/code/tensorflow/core/framework/types.h"><code>tensorflow/core/framework/types.h</code></a> 中的一些函数来定义（比如 <code>NumberTypes()</code>）。在本例中，属性 <code>t</code> 必须是下面一种数值类型：</p>
<pre><code class="lang-c++">  REGISTER_OP(&quot;NumberType&quot;)
      .Attr(&quot;t: numbertype&quot;);
</code></pre>
<p>   对于这个操作：</p>
<pre><code class="lang-python">   tf.number_type(t=tf.int32)  # 合法
   tf.number_type(t=tf.bool)   # 不合法
</code></pre>
<p>   列表可以和其他列表及单一类型组合。下面的操作允许属性 <code>t</code> 为任意数值类型或布尔类型：</p>
<pre><code class="lang-c++">  REGISTER_OP(&quot;NumberOrBooleanType&quot;)
      .Attr(&quot;t: {numbertype, bool}&quot;);
</code></pre>
<p>   对于这个操作：</p>
<pre><code class="lang-python">   tf.number_or_boolean_type(t=tf.int32)  # 合法
   tf.number_or_boolean_type(t=tf.bool)   # 合法
   tf.number_or_boolean_type(t=tf.string) # 不合法
</code></pre>
</li>
<li><p><code>int &gt;= &lt;n&gt;</code>：取值必须是整型，且要求大于等于 <code>&lt;n&gt;</code>，其中 <code>&lt;n&gt;</code> 是一个自然数。</p>
<p> 比如，下列操作注册中，指定了属性 <code>a</code> 必须为一个至少为 <code>2</code> 的值：</p>
<pre><code class="lang-c++">REGISTER_OP(&quot;MinIntExample&quot;)
    .Attr(&quot;a: int &gt;= 2&quot;);
</code></pre>
</li>
<li><p><code>list(&lt;type&gt;) &gt;= &lt;n&gt;</code>: 取值为<code>&lt;type&gt;</code> 类型的一个列表，其长度大于等于 <code>&lt;n&gt;</code>。</p>
<p> 比如，下列操作注册指定属性 <code>a</code> 是一个类型列表（要么是 <code>int32</code>，要么是 <code>float</code>），且要求长度大于等于 <code>3</code>：</p>
<pre><code class="lang-c++">REGISTER_OP(&quot;TypeListExample&quot;)
    .Attr(&quot;a: list({int32, float}) &gt;= 3&quot;);
</code></pre>
</li>
</ul>
<p>为设置一个属性的默认值（让它在生成代码中成为可选项），可以在最后加上 <code>= &lt;default&gt;</code>，如下面代码所示：</p>
<pre><code class="lang-c++">REGISTER_OP(&quot;AttrDefaultExample&quot;)
    .Attr(&quot;i: int = 0&quot;);
</code></pre>
<p>这种默认值的支持语法正是计算图的 GraphDef 定义的协议缓存表达中所用的语法。</p>
<p>下面的示例展示如何为所有类型指定默认值：</p>
<pre><code class="lang-c++">REGISTER_OP(&quot;AttrDefaultExampleForAllTypes&quot;)
   .Attr(&quot;s: string = &#39;foo&#39;&quot;)
   .Attr(&quot;i: int = 0&quot;)
   .Attr(&quot;f: float = 1.0&quot;)
   .Attr(&quot;b: bool = true&quot;)
   .Attr(&quot;ty: type = DT_INT32&quot;)
   .Attr(&quot;sh: shape = { dim { size: 1 } dim { size: 2 } }&quot;)
   .Attr(&quot;te: tensor = { dtype: DT_INT32 int_val: 5 }&quot;)
   .Attr(&quot;l_empty: list(int) = []&quot;)
   .Attr(&quot;l_int: list(int) = [2, 3, 5, 7]&quot;);
</code></pre>
<p><a href="https://www.tensorflow.org/api_docs/python/tf/DType"><code>tf.DType</code></a></p>
<h4>多态</h4>
<h5>类型多态性</h5>
<p>有些操作支持不同类型的输入或产生不同类型的输出，这时你可以在此操作的注册中为<a href="#输入和输出">一个输入或输出类型</a>指定<a href="#属性">一个属性</a>。通常，你还要为支持的每种类型注册一个 <code>OpKernel</code>。</p>
<p>比如，如果你想让 <code>ZeroOut</code> 操作既支持 <code>int32</code> 数值类型的张量，还要支持 <code>float</code> 类型，那么此操作的注册过程将类似于：</p>
<pre class="prettyprint"><code class="lang-cpp">
REGISTER\_OP("ZeroOut")
    <b>.Attr("T: {float, int32}")</b>
    .Input("to\_zero: <b>T</b>")
    .Output("zeroed: <b>T</b>");
</code></pre><p>现在，此操作在注册中指定了输入类型必须是 <code>float</code> 或 <code>int32</code>，而它的输出类型将保持一致，因为都是 <code>T</code> 类型。</p>
<blockquote><p><a id="naming"></a> 关于命名的备注：输入、输出和属性一般都应该使用蛇形命名。<br>
不过有一个例外情况，那就是属性被用作输入类型、或用于输入类型时。这样的属性会在操作被加入到计算图中自动推断出来，即它们不会在操作的函数中出现。比如，ZeroOut 最终的定义将产生一个如下的 Python 函数：</p>
<pre><code class="lang-python">def zero_out(to_zero, name=None):
  &quot;&quot;&quot;...
  参数：
    to_zero: 表示一个 `Tensor`。必须是两种类型之一： `float32`、 `int32`。
    name: 操作的名称（可选）

  返回值：
    一个 `Tensor`，与 `to_zero` 类型相同
  &quot;&quot;&quot;
</code></pre>
<p>如果 <code>to_zero</code> 中传入一个 <code>int32</code> 张量，则 <code>T</code> 自动被设置为 <code>int32</code> （实际上是 <code>DT_INT32</code>）。<br>
这时推断出来的属性的命名方式为首字母大小或单词首字母大写。</p>
<p>与这种情况不同的是，有时候我们需要为用一个类型属性来为操作指定输出类型：</p>
<pre><code class="lang-c++">REGISTER_OP(&quot;StringToNumber&quot;)
    .Input(&quot;string_tensor: string&quot;)
    .Output(&quot;output: out_type&quot;)
    .Attr(&quot;out_type: {float, int32} = DT_FLOAT&quot;);
    .Doc(R&quot;doc(
将输入张量中的每个字符串转换为指定的数值类型。
)doc&quot;);
</code></pre>
<p>这时，用户需要指定输出类型，如 Python 代码所示：</p>
<pre><code class="lang-python">def string_to_number(string_tensor, out_type=None, name=None):
  &quot;&quot;&quot;将输入张量中的每个字符串转换为指定的数值类型。

  参数：
    string_tensor: `string` 类型的一个 `Tensor`
    out_type: 可选的 `tf.DType`，即 `tf.float32` 和 `tf.int32` 二者之一，默认为 `tf.float32`。
    name: 操作名称（可选）

  返回值：
    类型为 `out_type` 的一个 `Tensor`
  &quot;&quot;&quot;
</code></pre>
</blockquote>
<pre class="prettyprint"><code class="lang-cpp">
\#include "tensorflow/core/framework/op_kernel.h"<br/>
class ZeroOut<b>Int32</b>Op : public OpKernel {
  // 和前面一样
};<br/>
class ZeroOut<b>Float</b>Op : public OpKernel {
 public:
  explicit ZeroOut<b>Float</b>Op(OpKernelConstruction\* context)
      : OpKernel(context) {}<br/>
  void Compute(OpKernelContext\* context) override {
    // 获得输入张量
    const Tensor& input\_tensor = context-&gt;input(0);
    auto input = input\_tensor.flat&lt;<b>float</b>&gt;();<br/>
    // 产生输出张量
    Tensor* output = NULL;
    OP\_REQUIRES\_OK(context,
                   context-&gt;allocate\_output(0, input_tensor.shape(), &output));
    auto output\_flat = output-&gt;template flat&lt;<b>float</b>&gt;();<br/>
    // 将输出张量中的所有元素设置为 0
    const int N = input.size();
    for (int i = 0; i &lt; N; i++) {
      output\_flat(i) = 0;
    }<br/>
    // 保留第一个输入值́
    if (N &gt; 0) output\_flat(0) = input(0);
  }
};<br/><b>
// 注意：TypeConstraint&lt;int32&gt;("T") 表示属性 `T` （定义在操作注册代码中）必须是 `int32` 类型的，
// 即将模板实例化了。</b>
REGISTER\_KERNEL\_BUILDER(
    Name("ZeroOut")
    .Device(DEVICE\_CPU)
    <b>.TypeConstraint&lt;int32&gt;("T"),</b>
    ZeroOutOp<b>Int32</b>);
<b>REGISTER\_KERNEL\_BUILDER(
    Name("ZeroOut")
    .Device(DEVICE\_CPU)
    .TypeConstraint&lt;float&gt;("T"),
    ZeroOutFloatOp);
</b></code></pre><blockquote><p>为了<a href="#后向兼容">后向兼容</a>，在将属性加到已有操作中时，你需要指定一个<a href="#默认值约束">默认值</a>：</p>
<pre class="prettyprint"><code class="lang-cpp">
REGISTER\_OP("ZeroOut")
  <b>.Attr("T: {float, int32} = DT_INT32")</b>
  .Input("to\_zero: T")
  .Output("zeroed: T")
</code></pre>
</blockquote>
<p>如果你还想添加更多类型，比如说 <code>double</code> 类型，你要稍微修改一下注册代码：</p>
<pre class="prettyprint"><code class="lang-cpp">
REGISTER\_OP("ZeroOut")
    <b>.Attr("T: {float, <b>double,</b> int32}")</b>
    .Input("to\_zero: <b>T</b>")
    .Output("zeroed: <b>T</b>");
</code></pre><p>为了避免像上面的代码一样为多个 <code>OpKernel</code> 编写冗余代码，你可以使用 C++ 模板。<br>
不过，你仍然需要为每一次加载注册一个内核（调用 <code>REGISTER_KERNEL_BUILDER</code>）。</p>
<pre class="prettyprint"><code class="lang-cpp">
<b>template &lt;typename T&gt;</b>
class ZeroOutOp : public OpKernel {
 public:
  explicit ZeroOutOp(OpKernelConstruction\* context) : OpKernel(context) {}<br/>
  void Compute(OpKernelContext\* context) override {
    // 获得输入张量
    const Tensor& input\_tensor = context-&gt;input(0);
    auto input = input\_tensor.flat<b>&lt;T&gt;</b>();<br/>
    // 产生输出张量
    Tensor* output = NULL;
    OP\_REQUIRES\_OK(context,
                   context-&gt;allocate\_output(0, input_tensor.shape(), &output));
    auto output\_flat = output-&gt;template flat<b>&lt;T&gt;</b>();<br/>
    // 将输出张量中的所有元素设置为 0
    const int N = input.size();
    for (int i = 0; i &lt; N; i++) {
      output\_flat(i) = 0;
    }<br/>
    // 保留第一个输入值́
    if (N &gt; 0) output\_flat(0) = input(0);
  }
};<br/>
// 注意：TypeConstraint&lt;int32&gt;("T") 表示属性 `T` （定义在操作注册代码中）必须是 `int32` 类型的，
// 即将模板实例化了。</b>
REGISTER\_KERNEL\_BUILDER(
    Name("ZeroOut")
    .Device(DEVICE\_CPU)
    .TypeConstraint&lt;int32&gt;("T"),
    <b>ZeroOutOp&lt;int32&gt;</b>);
REGISTER\_KERNEL\_BUILDER(
    Name("ZeroOut")
    .Device(DEVICE\_CPU)
    .TypeConstraint&lt;float&gt;("T"),
    <b>ZeroOutOp&lt;float&gt;</b>);
<b>REGISTER\_KERNEL\_BUILDER(
    Name("ZeroOut")
    .Device(DEVICE\_CPU)
    .TypeConstraint&lt;double&gt;("T"),
    ZeroOutOp&lt;double&gt;);
</b></code></pre><p>如果加载次数还不少，那你可以将注册放入宏中。</p>
<pre><code class="lang-c++">#include &quot;tensorflow/core/framework/op_kernel.h&quot;

#define REGISTER_KERNEL(type)                                       \
  REGISTER_KERNEL_BUILDER(                                          \
      Name(&quot;ZeroOut&quot;).Device(DEVICE_CPU).TypeConstraint&lt;type&gt;(&quot;T&quot;), \
      ZeroOutOp&lt;type&gt;)

REGISTER_KERNEL(int32);
REGISTER_KERNEL(float);
REGISTER_KERNEL(double);

#undef REGISTER_KERNEL
</code></pre>
<p>根据你为内核注册的类型列表的不同，你还可以使用 <a href="https://www.tensorflow.org/code/tensorflow/core/framework/register_types.h"><code>tensorflow/core/framework/register_types.h</code></a> 中提供的宏：</p>
<pre><code class="lang-c++">#include &quot;tensorflow/core/framework/op_kernel.h&quot;
#include &quot;tensorflow/core/framework/register_types.h&quot;

REGISTER_OP(&quot;ZeroOut&quot;)
    .Attr(&quot;T: realnumbertype&quot;)
    .Input(&quot;to_zero: T&quot;)
    .Output(&quot;zeroed: T&quot;);

template &lt;typename T&gt;
class ZeroOutOp : public OpKernel { ... };

#define REGISTER_KERNEL(type)                                       \
  REGISTER_KERNEL_BUILDER(                                          \
      Name(&quot;ZeroOut&quot;).Device(DEVICE_CPU).TypeConstraint&lt;type&gt;(&quot;T&quot;), \
      ZeroOutOp&lt;type&gt;)

TF_CALL_REAL_NUMBER_TYPES(REGISTER_KERNEL);

#undef REGISTER_KERNEL
</code></pre>
<h5>列表作为输入输出</h5>
<p>除了能够接受或产生不同类型之外，操作还消耗或产生数目不一的张量。</p>
<p>在下一个例子中，属性 <code>T</code> 保存了类型列表，并被用作输入 <code>in</code> 和输出 <code>out</code> 的类型。即输入和输出都是该类型的张量列表（并且输入输出张量的大小和类型都是完全一样的，因为它们都具有类型 <code>T</code>）。</p>
<pre><code class="lang-c++">REGISTER_OP(&quot;PolymorphicListExample&quot;)
    .Attr(&quot;T: list(type)&quot;)
    .Input(&quot;in: T&quot;)
    .Output(&quot;out: T&quot;);
</code></pre>
<p>你也可以对列表中元素的类型施加限制。在下一个例子中，输入是 <code>float</code> 或 <code>double</code> 类型张量的列表。比如，若输入类型是 <code>(float, double, float)</code>，而输出类型也必须是 <code>(float, double, float)</code>。</p>
<pre><code class="lang-c++">REGISTER_OP(&quot;ListTypeRestrictionExample&quot;)
    .Attr(&quot;T: list({float, double})&quot;)
    .Input(&quot;in: T&quot;)
    .Output(&quot;out: T&quot;);
</code></pre>
<p>如果你要求列表中所有张量的类型都相同，则你可以这样：</p>
<pre><code class="lang-c++">REGISTER_OP(&quot;IntListInputExample&quot;)
    .Attr(&quot;N: int&quot;)
    .Input(&quot;in: N * int32&quot;)
    .Output(&quot;out: int32&quot;);
</code></pre>
<p>此例中，输入是 <code>int32</code> 类型的张量的列表，其中 <code>int</code> 属性 <code>N</code> 用来指定此列表的长度。</p>
<p>我们也可以实现 <a href="#类型多态性">类型多态性</a>。在下一个示例中，输入是长度为 <code>N</code> 的张量列表，这些张量的类型为 <code>T</code>（但还没指定），而输出则为指定类型的单个张量：</p>
<pre><code class="lang-c++">REGISTER_OP(&quot;SameListInputExample&quot;)
    .Attr(&quot;N: int&quot;)
    .Attr(&quot;T: type&quot;)
    .Input(&quot;in: N * T&quot;)
    .Output(&quot;out: T&quot;);
</code></pre>
<p>默认情况下，张量列表的长度至少为 1。你可以用 <a href="#默认值约束">相应属性上的 <code>"&gt;="</code> 约束</a> 来修改默认值。在下一个示例中，输入是长度至少为 2 的 <code>int32</code> 张量列表：</p>
<pre><code class="lang-c++">REGISTER_OP(&quot;MinLengthIntListExample&quot;)
    .Attr(&quot;N: int &gt;= 2&quot;)
    .Input(&quot;in: N * int32&quot;)
    .Output(&quot;out: int32&quot;);
</code></pre>
<p>同样的语法也可以用到 <code>"list(type)"</code> 类型的属性上：</p>
<pre><code class="lang-c++">REGISTER_OP(&quot;MinimumLengthPolymorphicListExample&quot;)
    .Attr(&quot;T: list(type) &gt;= 3&quot;)
    .Input(&quot;in: T&quot;)
    .Output(&quot;out: T&quot;);
</code></pre>
<h4>输入和输出</h4>
<p>下面对前面的示例做个总结，一个操作注册可以指定多个输入输出：</p>
<pre><code class="lang-c++">REGISTER_OP(&quot;MultipleInsAndOuts&quot;)
    .Input(&quot;y: int32&quot;)
    .Input(&quot;z: float&quot;)
    .Output(&quot;a: string&quot;)
    .Output(&quot;b: int32&quot;);
</code></pre>
<p>每个输入或输出的规范的格式如下：</p>
<pre><code>&lt;name&gt;: &lt;io-type-expr&gt;
</code></pre>
<p>其中 <code>&lt;name&gt;</code> 以字母开头，可以由字母、数字和下划线组成。<code>&lt;io-type-expr&gt;</code> 是下列表达式之一：</p>
<ul>
<li><p><code>&lt;type&gt;</code>：支持的输入类型，比如 <code>float</code>、<code>int32</code>、<code>string</code>。这个表达式指定了 <code>type</code> 类型的单个张量。</p>
<p><a href="https://www.tensorflow.org/api_docs/python/tf/DType"><code>tf.DType</code></a></p>
<pre><code class="lang-c++">REGISTER_OP(&quot;BuiltInTypesExample&quot;)
    .Input(&quot;integers: int32&quot;)
    .Input(&quot;complex_numbers: complex64&quot;);
</code></pre>
</li>
<li><p><code>&lt;attr-type&gt;</code>：一个<a href="#属性">属性</a>的名称，此属性的类型可以是 <code>type</code> 或 <code>list(type)</code>（可以有类型限制）。这个语法可以实现<a href="#多态">多态操作</a>。</p>
<pre><code class="lang-c++">REGISTER_OP(&quot;PolymorphicSingleInput&quot;)
    .Attr(&quot;T: type&quot;)
    .Input(&quot;in: T&quot;);

REGISTER_OP(&quot;RestrictedPolymorphicSingleInput&quot;)
    .Attr(&quot;T: {int32, int64}&quot;)
    .Input(&quot;in: T&quot;);
</code></pre>
<p> 引用类型为 <code>list(type)</code> 的属性可以让你接受一个张量序列。</p>
<pre><code class="lang-c++">REGISTER_OP(&quot;ArbitraryTensorSequenceExample&quot;)
    .Attr(&quot;T: list(type)&quot;)
    .Input(&quot;in: T&quot;)
    .Output(&quot;out: T&quot;);

REGISTER_OP(&quot;RestrictedTensorSequenceExample&quot;)
    .Attr(&quot;T: list({int32, int64})&quot;)
    .Input(&quot;in: T&quot;)
    .Output(&quot;out: T&quot;);
</code></pre>
<p> 注意，输出 <code>out</code> 中的张量的类型和数目与输入 <code>in</code> 是一样的，因为它们都是 <code>T</code> 类型。</p>
</li>
<li><p><a href="https://www.tensorflow.org/api_docs/python/tf/DType"><code>tf.DType</code></a></p>
<pre><code class="lang-c++">REGISTER_OP(&quot;Int32SequenceExample&quot;)
    .Attr(&quot;NumTensors: int&quot;)
    .Input(&quot;in: NumTensors * int32&quot;)
</code></pre>
<p> 此操作接受任意类型的张量列表，只要它们的类型都一样：</p>
<pre><code class="lang-c++">REGISTER_OP(&quot;SameTypeSequenceExample&quot;)
    .Attr(&quot;NumTensors: int&quot;)
    .Attr(&quot;T: type&quot;)
    .Input(&quot;in: NumTensors * T&quot;)
</code></pre>
</li>
<li><p>对单个张量的引用：<code>Ref(&lt;type&gt;)</code>，其中 <code>&lt;type&gt;</code> 是上述类型中的一种。</p>
</li>
</ul>
<blockquote><p>关于命名的备注：输入的类型中用到的任何属性都会被推断出来。按惯例，这些被推断的属性名要首字线大写（比如 <code>T</code> 或 <code>N</code>）。其它情况下，输入、输出和属性的名称和函数参数命名方式一致，比如 <code>num_outputs</code>。更多细节，参考 <a href="#命名">前面关于命名的备注</a>。</p>
</blockquote>
<p>更多细节，参考 <a href="https://www.tensorflow.org/code/tensorflow/core/framework/op_def_builder.h"><code>tensorflow/core/framework/op_def_builder.h</code></a>。</p>
<h4>后向兼容性</h4>
<p>假设你已经编写了一个很好的定制操作，并分享给他人，让你的客户开心地使用了。然而，你还想要进一步修改这个操作。</p>
<p><a href="//xitu.github.io/tensorflow-docs-web/programmers_guide/version_compat.html#compatibility_of_graphs_and_checkpoints">TensorFlow 版本兼容性</a></p>
<p>保持后向兼容性的方法有很多，下面列出了一些：</p>
<ol>
<li><p>添加到一个操作的任何新属性必须定义默认值，而在默认值下，此操作的行为必须与原来相同。要将操作从非多态转换为多态，你<em>必须</em>为新属性指定默认值，让它在默认情况下保持原来的行为。比如，如果你的操作为：</p>
<pre><code>REGISTER_OP("MyGeneralUnaryOp")
    .Input("in: float")
    .Output("out: float");
</code></pre>
<p> 你可以在保持后向兼容的情况下让它变得多态：</p>
<pre><code>REGISTER_OP("MyGeneralUnaryOp")
    .Input("in: T")
    .Output("out: T")
    .Attr("T: numerictype = DT_FLOAT");
</code></pre>
</li>
<li><p>对于一个属性，你总是可以安全地施加更严格的约束。比如，你可以将 <code>{int32, int64}</code> 变成<code>{int32, int64, float}</code> 或 <code>type</code> 。你也可以将 <code>{"apple", "orange"}</code>变成<code>{"apple", "banana", "orange"}</code> 或 <code>string</code> 。</p>
</li>
<li><p>你可以将单个输入/输出变成列表形式的输入/输出，前提是列表类型的默认值与原来的接口一致。</p>
</li>
<li><p>你可以添加一个新的列表形式的输入/输出，只要它的默认值为空。</p>
</li>
<li><p>将你创建新创建的任何操作放在命名空间中，即在操作前面加上前缀以区别于工程中的其它操作。这可以让你的操作避免与 TensorFlow 未来版本中新引入的操作相冲突。</p>
</li>
<li><p>提前计划好！尝试构想此操作的未来用途。有些接口修改无法以兼容方式修改（比如，将相同类型列表变成变化类型列表）。</p>
</li>
</ol>
<p>安全和不安全修改的完整列表可以在源码 <a href="https://www.tensorflow.org/code/tensorflow/core/framework/op_compatibility_test.cc"><code>tensorflow/core/framework/op_compatibility_test.cc</code></a> 中找到。如果你无法在兼容要求下修改此操作，那么最好是另起炉灶，创建一个新的操作，取一个新的名字，来表示你的新的语义。</p>
<p><a href="//xitu.github.io/tensorflow-docs-web/programmers_guide/version_compat.html#compatibility_of_graphs_and_checkpoints">TensorFlow 版本兼容性</a></p>
<h3>GPU 支持</h3>
<p>你可以实现不同的内核操作(OpKernel)，然后一个注册到 CPU 上，另一个注册到 GPU 上,就像你可以<a href="#多态">为不同的类型注册内核</a>一样。TensorFlow提供了多个支持 GPU 的内核的例子，参见源码<a href="https://www.tensorflow.org/code/tensorflow/core/kernels/"><code>tensorflow/core/kernels</code></a>。注意，有些内核的 CPU 版本在一个 <code>.cc</code> 文件中，其 GPU 版本在一个 <code>_gpu.cu.cc</code> 文件中，它们共享的代码则在一个 <code>.h</code> 文件中。</p>
<p><a href="https://www.tensorflow.org/api_docs/python/tf/pad"><code>tf.pad</code></a></p>
<p>值得注意的一点是，即使使用的是 <code>pad</code> 操作的 GPU 内核版本，它仍然需要用到 CPU 内存中的 <code>"paddings"</code> 输入。为标记这种 CPU 上的输入或输出，在内核注册时添加一个 <code>HostMemory()</code> 调用，比如：</p>
<pre><code class="lang-c++">#define REGISTER_GPU_KERNEL(T)                         \
  REGISTER_KERNEL_BUILDER(Name(&quot;Pad&quot;)                  \
                              .Device(DEVICE_GPU)      \
                              .TypeConstraint&lt;T&gt;(&quot;T&quot;)  \
                              .HostMemory(&quot;paddings&quot;), \
                          PadOp&lt;GPUDevice, T&gt;)
</code></pre>
<h4>为 GPU 设备编译内核</h4>
<p>代码 <a href="https://www.tensorflow.org/code/tensorflow/examples/adding_an_op/cuda_op_kernel.cu.cc">cuda_op_kernel.cu.cc</a> 中给出了使用 CUDA 内核实现操作的一个例子。<code>tf_custom_op_library</code> 接受一个 <code>gpu_srcs</code> 参数，其中包含 CUDA 内核 (<code>*.cu.cc</code> 文件)的源文件列表。如果你使用的是 Tensorflow 的二进制安装，这些 CUDA 内核代码必须用 NVIDIA 的 <code>nvcc</code> 编译器进行编译。为了将 <a href="https://www.tensorflow.org/code/tensorflow/examples/adding_an_op/cuda_op_kernel.cu.cc">cuda_op_kernel.cu.cc</a>和<a href="https://www.tensorflow.org/code/tensorflow/examples/adding_an_op/cuda_op_kernel.cc">cuda_op_kernel.cc</a>这两个源码编译成一个动态加载库，你需要使用如下命令：</p>
<pre><code class="lang-bash">nvcc -std=c++11 -c -o cuda_op_kernel.cu.o cuda_op_kernel.cu.cc \
  ${TF_CFLAGS[@]} -D GOOGLE_CUDA=1 -x cu -Xcompiler -fPIC

g++ -std=c++11 -shared -o cuda_op_kernel.so cuda_op_kernel.cc \
  cuda_op_kernel.cu.o ${TF_CFLAGS[@]} -fPIC -lcudart ${TF_LFLAGS[@]}
</code></pre>
<p>通过 <code>tf.load_op_library</code> 函数，上述命令产生的 <code>cuda_op_kernel.so</code> 可以像通常的动态链接库一样在 Python 中加载。<br>
注意，如果 CUDA 库没有安装在 <code>/usr/local/lib64</code> 中，你需要在 上面第二个命令（g++）中显式指定其路径。比如，你的 CUDA 安装在 <code>/usr/local/cuda-8.0</code> 中，则需要在命令行中添加 <code>-L /usr/local/cuda-8.0/lib64/</code>。</p>
<blockquote><p>   注意，在某些 Linux 设置中，<code>nvcc</code> 编译步骤还需要其他选项。将 <code>-D_MWAITXINTRIN_H_INCLUDED</code> 添加到 nvcc 命令行以避免 <code>mwaitxintrin.h</code> 中的错误。</p>
</blockquote>
<h3>在 Python 中实现梯度计算</h3>
<p><a href="//xitu.github.io/tensorflow-docs-web/api_guides/python/train.html#gradient_computation">Training</a></p>
<p>在数学上，如果一个操作计算 \(y = f(x)\)，为它注册的梯度操作将损失函数 \(L\) 关于 \(y\) 的梯度 \(\partial L/ \partial y\) 转化为关于 \(x\) 的梯度 \(\partial L/ \partial x\)，它使用的是链式法则：<br>
$$\frac{\partial L}{\partial x}    = \frac{\partial L}{\partial y} \frac{\partial y}{\partial x}    = \frac{\partial L}{\partial y} \frac{\partial f}{\partial x}.$$</p>
<p>以 <code>ZeroOut</code> 为例，输入中只有一项会影响输出，所以关于输入的梯度是一个稀疏的 "one hot" 张量。代码如下：</p>
<pre><code class="lang-python">from tensorflow.python.framework import ops
from tensorflow.python.ops import array_ops
from tensorflow.python.ops import sparse_ops
@ops.RegisterGradient(&quot;ZeroOut&quot;)
def _zero_out_grad(op, grad):  
    &quot;&quot;&quot; `zero_out` 的梯度
    参数:    
      op: 待求微分的 `zero_out` 操作，通过它，我们可以找到原操作的输入输出。    
      grad: 关于 `zero_out` 操作的输出的梯度。
    返回值:    
      关于 `zero_out` 输入的梯度。  
    &quot;&quot;&quot;  
    to_zero = op.inputs[0]  
    shape = array_ops.shape(to_zero)  
    index = array_ops.zeros_like(shape)  
    first_grad = array_ops.reshape(grad, [-1])[0]  
    to_zero_grad = sparse_ops.sparse_to_dense([index], shape, first_grad, 0)  
    return [to_zero_grad]  # 只有一个张量的列表，因为我们只有一个输入
</code></pre>
<p><a href="https://www.tensorflow.org/api_docs/python/tf/RegisterGradient"><code>tf.RegisterGradient</code></a></p>
<ul>
<li><p><a href="https://www.tensorflow.org/api_docs/python/tf/Operation/get_attr"><code>tf.Operation.get_attr</code></a></p>
</li>
<li><p>如果操作有多个输出，其梯度函数的参数为 <code>op</code> 和 <code>grads</code>，其中 <code>grads</code> 是关于每个输出的梯度。此梯度函数的返回值为一个张量列表，表示的关于每个输入的梯度。</p>
</li>
<li>如果对某个输入没有良定义的梯度，比如用作指标的整数输入，相应的梯度应该为 <code>None</code>。比如，一个操作的一个输入是浮点型张量 <code>x</code>，<br>
另一个输入是一个整数指标 <code>i</code>，则梯度函数应该返回 <code>[x_grad, None]</code>。</li>
<li>如果一个操作根本就没有任何有意义的梯度，那么就没有必要注册梯度函数了。只要你不会用到操作的梯度，不注册也不会有什么问题。在有些情况下，一个操作没有良定义的梯度，但可能会参与到梯度计算中。在这种情况下，可以使用 <code>ops.NotDifferentiable</code> 来自动反向传播零值。</li>
</ul>
<p>注意，调用梯度函数时，只能访问到操作的数据流图，而不是张量数据本身。因此，所有梯度计算都必须使用其它 TensorFlow 操作执行，以便在计算图执行时运行。</p>
<h3>C++ 中的形状函数</h3>
<p>TensorFlow API 有一个功能叫做"形状推断"，可以无需执行计算图而获得张量的形状信息。形状推断是由"形状函数"来支撑的，每个操作类型都会在其 C++ <code>REGISTER_OP</code> 声明中注册形状函数，它们有两种作用：在计算图的构造函数中声明输入的形状是兼容的，为输出指定形状。</p>
<p>形状函数定义为 <code>shape_inference::InferenceContext</code> 类上的操作。比如，在 ZeroOut 的形状函数中：</p>
<pre><code class="lang-c++">    .SetShapeFn([](::tensorflow::shape_inference::InferenceContext* c) {
      c-&gt;set_output(0, c-&gt;input(0));
      return Status::OK();
    });
</code></pre>
<p><code>c-&gt;set_output(0, c-&gt;input(0));</code> 声明第一个输出的形状必须为第一个输入的形状。如果输出是按上面示例中的索引选择的，则 <code>set_output</code> 的第二个参数应该是一个 <code>ShapeHandle</code> 对象。你可以通过默认构造函数来创建一个空的 <code>ShapeHandle</code> 对象。索引为 <code>idx</code> 的输入的 <code>ShapeHandle</code> 对象可通过 <code>c-&gt;input(idx)</code> 来获得。</p>
<p>TensorFlow 已经提供了大量的通用形状函数，可适用于许多操作，比如 <code>shape_inference::UnchangedShape</code> 可在源码 <a href="https://www.tensorflow.org/code/tensorflow/core/framework/common_shape_fns.h">common_shape_fns.h</a> 中找到，其用法如下：</p>
<pre><code class="lang-c++">REGISTER_OP(&quot;ZeroOut&quot;)
    .Input(&quot;to_zero: int32&quot;)
    .Output(&quot;zeroed: int32&quot;)
    .SetShapeFn(::tensorflow::shape_inference::UnchangedShape);
</code></pre>
<p>一个形状函数也可用于约束输入的形状。对于 <a href="#validation">具有矢量形状约束的 <code>ZeroOut</code> 版本</a>，其形状函数定义如下：</p>
<pre><code class="lang-c++">    .SetShapeFn([](::tensorflow::shape_inference::InferenceContext* c) {
      ::tensorflow::shape_inference::ShapeHandle input;
      TF_RETURN_IF_ERROR(c-&gt;WithRank(c-&gt;input(0), 1, &amp;input));
      c-&gt;set_output(0, input);
      return Status::OK();
    });
</code></pre>
<p><code>WithRank</code> 函数验证输入形状 <code>c-&gt;input(0)</code> 是否有一个精确的维度（或者如果输入形状未知，则输出形状将是一个未知维度的向量）。</p>
<p>对于<a href="#多态">具有多个输入的多态</a>操作，可以使用 <code>InferenceContext</code> 的成员函数来确定需要检查的形状数目，并用 <code>Merge</code> 成员函数来验证这些形状都是兼容的（或者用 <code>InferenceContext::GetAttr</code> 访问表示长度的属性，此函数可以访问操作的属性）。</p>
<pre><code class="lang-c++">    .SetShapeFn([](::tensorflow::shape_inference::InferenceContext* c) {
      ::tensorflow::shape_inference::ShapeHandle input;
      ::tensorflow::shape_inference::ShapeHandle output;
      for (size_t i = 0; i &lt; c-&gt;num_inputs(); ++i) {
        TF_RETURN_IF_ERROR(c-&gt;WithRank(c-&gt;input(i), 2, &amp;input));
        TF_RETURN_IF_ERROR(c-&gt;Merge(output, input, &amp;output));
      }
      c-&gt;set_output(0, output);
      return Status::OK();
    });
</code></pre>
<p>由于形状推断是可选特征，且张量的形状可能会动态改变，因此形状函数必须能够处理任意输入可能的形状信息不完整的情况。<a href="https://www.tensorflow.org/code/tensorflow/core/framework/shape_inference.h"><code>InferenceContext</code></a> 的 <code>Merge</code> 方法允许在两个形状信息不完整的情况下（至少有一个不完整）断言它们是相同的。TensorFlow 的所有核心操作都定义了形状函数，并提供了许多不同的用法示例。</p>
<p><code>InferenceContext</code> 类中有很多可用于定义形状函数操作的函数。比如，你可以使用 <code>InferenceContext::Dim</code> 和 <code>InferenceContext::WithValue</code> 来验证一个特定的维度是否具有一个特定的值；我们还可以用 <code>InferenceContext::Add</code> 和 <code>InferenceContext::Multiply</code> 指定输出维度为两个输入维度的和 / 乘积。参见 <code>InferenceContex</code> 类的定义中所有可用的形状操作方法。下面的例子将第一个输出的形状设置为 (n,3)，将第一个输入的形状设置为 (n,...)。</p>
<pre><code class="lang-c++">.SetShapeFn([](::tensorflow::shape_inference::InferenceContext* c) {
    c-&gt;set_output(0, c-&gt;Matrix(c-&gt;Dim(c-&gt;input(0), 0), 3));
    return Status::OK();
});
</code></pre>
<p>对于复杂的形状函数，应该考虑添加一个测试，来验证多个输入形状组合可产生预期的输出形状组合。这种测试的编写方法参见源码 <a href="https://www.tensorflow.org/code/tensorflow/core/ops/array_ops_test.cc">core ops tests</a>。（<code>INFER_OK</code> 和 <code>INFER_ERROR</code> 的语法会让人感觉有点神秘，不过还是在测试中尽量让表示输入输出形状的规范简洁一些。目前，可以在已有的测试中看看注释，了解如何编写形状的规范。）</p>

        </main>
    </div>
</div>
<!-- Content end-->

<!-- Footer start -->
<footer class="footer">
    <div class="container">
        <div>如果您发现本页面存在错误或可以改进，请<a href="https://github.com/xitu/tensorflow-docs/blob/zh-hans/extend/adding_an_op.md" target="_blank">点击此处</a>帮助我们改进。本页贡献者：<span id="contributors"></span></div>
        <hr/>
        <div class="text-center official-links">
            <a href="https://www.tensorflow.org"><img
                    src="https://www.tensorflow.org/_static/b1fb9a8564/images/tensorflow/lockup.png" height="20"/></a>
            <a href="https://github.com/xitu/tensorflow-docs"><img
                    src="https://assets-cdn.github.com/images/modules/logos_page/GitHub-Logo.png" height="20"></a>
            <a href="https://juejin.im"><img src="//xitu.github.io/tensorflow-docs-web/assets/imgs/logo_app_white.png" height="20"/></a>
        </div>
    </div>
</footer>
<script>
    var contributors = [{'徐键': ''}, {'leviding': 'https://avatars3.githubusercontent.com/u/26959437?v=4'}]
</script>
<!-- Footer end -->
</body>
<script src="//cdn.bootcss.com/jquery/3.3.1/jquery.slim.min.js" type="text/javascript"></script>
<script src="//cdn.bootcss.com/highlight.js/9.12.0/highlight.min.js" type="text/javascript"></script>
<script src="//xitu.github.io/tensorflow-docs-web/assets/js/main.js" type="text/javascript"></script>
</html>
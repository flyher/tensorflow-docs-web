<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
<html>
<head>
    <meta http-equiv="Content-Type" content="text/html;charset=UTF-8">
    <title>TensorFlow Lite 简介</title>
    <link href="//tensorflow.juejin.im/assets/css/bootstrap.min.css" rel="stylesheet">
    <link href="//tensorflow.juejin.im/assets/css/main.css" rel="stylesheet">
    <link rel="stylesheet" href="//tensorflow.juejin.im/assets/css/highlight.js.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.css" />
</head>
<body>
<!-- Header start -->
<nav class="navbar navbar-expand-lg navbar-light bg-light">
    <a class="navbar-brand" href="//tensorflow.juejin.im">TensorFlow</a>
    <button class="navbar-toggler" type="button" aria-expanded="false" aria-label="Menu"
            onclick="$('.collapse').toggle()">
        <span class="navbar-toggler-icon"></span>
    </button>

    <div class="collapse navbar-collapse">
        <ul class="navbar-nav mr-auto">
        </ul>
        <form class="form-inline my-2 my-lg-0 my-md-0">
            <input class="form-control mr-sm-2" id="search" type="search" placeholder="Search" aria-label="Search">
        </form>
    </div>
</nav>
<script>
    var head = [{'link': '//tensorflow.juejin.im/extend/index.html', 'name': '扩展', 'selected': 0}, {'link': '//tensorflow.juejin.im/install/index.html', 'name': '安装 TensorFlow', 'selected': 0}, {'link': '//tensorflow.juejin.im/deploy/index.html', 'name': '部署', 'selected': 0}, {'link': '//tensorflow.juejin.im/about/index.html', 'name': '关于 TensorFlow', 'selected': 0}, {'link': '//tensorflow.juejin.im/get_started/index.html', 'name': '开始', 'selected': 0}, {'link': '//tensorflow.juejin.im/mobile/index.html', 'name': '概述', 'selected': 0}, {'link': '//tensorflow.juejin.im/tutorials/index.html', 'name': '教程', 'selected': 0}, {'link': '//tensorflow.juejin.im/javascript/index.html', 'name': 'JavaScript', 'selected': 0}, {'link': '//tensorflow.juejin.im/performance/index.html', 'name': '性能', 'selected': 0}, {'link': '//tensorflow.juejin.im/community/index.html', 'name': '社区', 'selected': 0}, {'link': '//tensorflow.juejin.im/programmers_guide/index.html', 'name': '开发者指南', 'selected': 0}]
</script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-92630037-8"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-92630037-8');
</script>

<!-- Header end -->

<!-- Content start-->
<div class="container-fluid">
    <div class="row">
        
        <main role="main" class="col-12 col-md-9 col-xl-8 py-md-3 pl-md-5 bd-content">
            <h1 id="toc-0">TensorFlow Lite 简介</h1>
<p>TensorFlow Lite 是 TensorFlow 移动和嵌入式设备轻量级解决方案。它使设备机器学习具有低延迟和更小的二进制体积。TensorFlow Lite 同时支持 <a href="https://developer.android.com/ndk/guides/neuralnetworks/index.html">Android 神经网络 API</a>的硬件加速.</p>
<p>TensorFlow Lite 使用多项技术降低延迟，例如移动 app 内核优化、pre-fused 激活、允许更快更小（定点）模型的量化内核。</p>
<p>目前大部分 TensorFlow Lite 文档放在 <a href="https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/lite">Github</a>上。</p>
<h2 id="toc-1">TensorFlow Lite 都包含什么？</h2>
<p>TensorFlow Lite 支持一系列量子和浮点的核心运算符,并针对移动平台进行了优化。它结合 pre-fused 激活和其他技术来进一步提高性能和量化精度。此外，TensorFlow Lite 还支持在模型中使用自定义操作。</p>
<p>TensorFlow Lite 基于 <a href="https://google.github.io/flatbuffers/">FlatBuffers</a>定义了一个新的模型文件格式。FlatBuffers 是一个开源的高效的跨平台序列化库。它与 <a href="https://developers.google.com/protocol-buffers/?hl=en">protocol buffers</a>类似,但主要区别是 FlatBuffers 常与 per-object 内存分配相结合在您直接访问数据时不需要再次解析包。此外，FlatBuffers 的代码体积比 protocol buffers 小很多。</p>
<p>TensorFlow Lite 拥有一个新的移动设备优化的解释器保证应用程序的精简和快速。解释器使用静态图形排序和自定义（less-dynamic）内存分配器来确保最小的负载，初始化和执行延迟。</p>
<p>TensorFlow Lite 针对支持的设备提供了一个利用硬件加速的接口。通过 Android 神经网络库，作为 Android O-MR1 的一部分发布。</p>
<h2 id="toc-2">为什么我们需要针对移动端的库?</h2>
<p>机器学习正在改变计算模式，我们看到了移动和嵌入式设备上使用的新趋势。消费者的期望也趋向于与他们的设备自然而友好地互动，由相机和语音交互模式驱动。</p>
<p>有几个因素促成了这个领域：</p>
<ul>
<li><p>硅层的创新为硬件加速带来了新的可能性，像 Android Neural Networks API 这样的框架可以很容易地利用这些特性。</p>
</li>
<li><p>实时计算机视觉和口头语言理解的最新进展：一些 mobile-optimized 评测模型已开放源代码(例如 MobileNets，SqueezeNet)。</p>
</li>
<li><p>广泛使用的智能设备为 on-device 智能创造了新的可能性。</p>
</li>
<li><p>更强大的用户隐私保护方案，使用户数据不需要离开移动设备。</p>
</li>
<li><p>能够在设备不需要连接到网络的情况下提供"离线"用例。</p>
</li>
</ul>
<p>我们相信下一波机器学习应用将在移动和嵌入式设备上重大进步。</p>
<h2 id="toc-3">TensorFlow Lite 开发者预览版亮点</h2>
<p>TensorFlow Lite 作为开发者预览版亮点，包括以下内容：</p>
<ul>
<li><p>一组核心操作符，既有量子化也有浮点值，其中很多已经针对移动平台进行了优化。这些可以用来创建和运行自定义模型。开发人员也可以编写自己的自定义操作符并在模型中使用它们。</p>
</li>
<li><p>基于 <a href="https://google.github.io/flatbuffers/">FlatBuffers</a>模型文件格式。</p>
</li>
<li><p>On-device 解释器，内核经过优化，可在移动设备上更快执行。</p>
</li>
<li><p>TensorFlow 转换器将 TensorFlow 训练好的模型转换为 TensorFlow Lite 格式。</p>
</li>
<li><p>更小的体积：当所有支持的操作符链接时，TensorFlow Lite 小于 300 KB，而仅使用支持 Inception V3 和 Mobilenet 所需的操作符时，TensorFlow Lite 小于 200 KB。</p>
</li>
<li><p><strong>预设模型:</strong></p>
<p>以下所有预设模型均可保证开箱即用：</p>
<ul>
<li><p>Inception V3 是一种用于检测图像中存在的主要对象的流行模型。</p>
</li>
<li><p><a href="https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet_v1.md">MobileNets</a>,<br>
一系列移动优先计算机视觉模型，旨在有效提高准确性，同时注重 on-device 或嵌入式应用程序的有限资源。它们很小，低延迟，低功耗，模型参数化，以满足各种用例的资源约束。它们可以建立在分类，检测，嵌入和分割之上。MobileNet 模型比较小，但是比 Inception V3 <a href="https://research.googleblog.com/2017/06/mobilenets-open-source-models-for.html">准确度更低</a>。</p>
</li>
<li><p>在设备智能回复上, 提供能通过建议上下文相关的消息来回复传入的文本消息的 one-touch 的 on-device 模型，该模型专为内存受限的设备而建立，如手表和手机，<br>
它已被成功应用到 <a href="https://research.googleblog.com/2017/02/on-device-machine-intelligence.html">Android Wear 智能回复</a>所有官方和第三方应用.</p>
</li>
</ul>
</li>
<li><p>MobileNet 模型量子版本, 其运行速度比 CPU 上的 non-quantized（浮点）版本快。</p>
</li>
<li><p>新的 Android 演示应用程序来说明使用 TensorFlow Lite 与量子化的 MobileNet 模型进行对象分类。</p>
</li>
<li><p>Java 和 C++ API 支持</p>
</li>
</ul>
<p>注意：这是一个开发者版本，很可能在即将到来的版本中会有 API 的变化。我们不保证向后或向前兼容这个版本。</p>
<h2 id="toc-4">入门</h2>
<p>我们建议您使用上述的 TensorFlow Lite 的 pre-tested 模型。如果有一个现有的模型，则需要测试模型是否兼容转换器和支持的操作集。要测试你的模型，请看 <a href="https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/lite">GitHub 文档</a>。</p>
<h3 id="toc-5">为自定义数据集重置 Inception-V3 或 MobileNet</h3>
<p>这里的 pre-trained 模型已经在 ImageNet 数据集上进行了训练 ，该数据集由 1000 个预定义的类组成。如果这些类不适合您的用例，那么您需要重新训练这些模型。这种从一个已经被训练过的问题的模型开始，然后在类似的问题上进行再训练叫做迁移学习。从头开始深入学习可能需要几天，但迁移学习可以很快完成。为了做到这一点，您需要生成标有相关类的自定义数据集。</p>
<p><a href="https://codelabs.developers.google.com/codelabs/tensorflow-for-poets/">TensorFlow for Poets</a> 一步一步实现了这个过程，再训练代码支持浮点和量化推理的再训练。</p>
<h2 id="toc-6">TensorFlow Lite 架构</h2>
<p>下图显示了 TensorFlow Lite 的架构设计：</p>
<p><img src="https://www.tensorflow.org/images/tflite-architecture.jpg" alt="tensorflow lite 架构"></p>
<p>在硬盘上练习 TensorFlow 模型, 您需要使用 TensorFlow Lite 转换器把模型转换为 TensorFlow Lite（<code>.tflite</code>）文件格式。然后，您可以在移动应用程序中使用该转换后的文件。</p>
<p>部署 TensorFlow Lite 模型文件使用：</p>
<ul>
<li><p>Java API: 围绕 Android 上 C++ API 的便捷包装。</p>
</li>
<li><p>C++ API: 加载 TensorFlow Lite 模型文件并调用解释器。Android 和 iOS 都提供相同的库。</p>
</li>
<li><p>解释器: 使用一组内核来执行模型。解释器支持选择性内核加载;没有内核，只有 100 KB，加载了所有内核，有 300 KB。这比 TensorFlow Mobile 要求的 1.5 M 的显著减少。</p>
</li>
<li><p>在选定的 Android 设备上，解释器将使用 Android 神经网络 API 进行硬件加速，如果没有可用的，则默认为 CPU 执行。</p>
</li>
</ul>
<p>您也可以使用解释器可以使用的 C++ API 来实现定制的内核。</p>
<h2 id="toc-7">未来工作</h2>
<p>在未来的版本中，TensorFlow Lite 支持更多的模型和内置运算符, 包含定点和浮点模型的性能改进，改进工具以简化开发者工作流程以及支持其他更小的设备等等。随着我们的不断发展，我们希望 TensorFlow Lite 能够大大简化针对小型设备定位模型的开发者体验。</p>
<p>未来的计划包括使用专门的机器学习硬件，以获得特定设备上特定型号的最佳性能。</p>
<h2 id="toc-8">下一步</h2>
<p>对于开发人员的预览，我们的大部分文档都在 GitHub 上。请查看 <a href="https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/lite">TensorFlow Lite 库</a>在 GitHub 上获取更多信息和代码示例，演示应用程序等等。</p>

        </main>
        <div class="d-none d-xl-block col-xl-2 bd-toc">
        <ul id="table-of-content">
<li><a href="#toc-0">TensorFlow Lite 简介</a><ul>
<li><a href="#toc-1">TensorFlow Lite 都包含什么？</a></li>
<li><a href="#toc-2">为什么我们需要针对移动端的库?</a></li>
<li><a href="#toc-3">TensorFlow Lite 开发者预览版亮点</a></li>
<li><a href="#toc-4">入门</a></li>
<li><a href="#toc-6">TensorFlow Lite 架构</a></li>
<li><a href="#toc-7">未来工作</a></li>
<li><a href="#toc-8">下一步</a></li>
</ul>
</li>
</ul>

        </div>
    </div>
</div>
<!-- Content end-->

<!-- Footer start -->
<footer class="footer">
    <div class="container">
        <div>如果您发现本页面存在错误或可以改进，请<a href="https://github.com/xitu/tensorflow-docs/blob/zh-hans/mobile/tflite/index.md" target="_blank">点击此处</a>帮助我们改进。本页贡献者：<span id="contributors"></span></div>
        <hr/>
        <div class="text-center official-links">
            <a href="https://www.tensorflow.org"><img
                    src="https://www.tensorflow.org/_static/b1fb9a8564/images/tensorflow/lockup.png" height="20"/></a>
            <a href="https://github.com/xitu/tensorflow-docs"><img
                    src="https://assets-cdn.github.com/images/modules/logos_page/GitHub-Logo.png" height="20"></a>
            <a href="https://juejin.im"><img src="//tensorflow.juejin.im/assets/imgs/logo_app_white.png" height="20"/></a>
        </div>
    </div>
</footer>
<script>
    var contributors = [{'sunhaokk': 'https://avatars3.githubusercontent.com/u/21034154?v=4'}, {'leviding': 'https://avatars3.githubusercontent.com/u/26959437?v=4'}]
</script>
<!-- Footer end -->
</body>
<script src="//tensorflow.juejin.im/assets/js/jquery.slim.min.js" type="text/javascript"></script>
<script src="//tensorflow.juejin.im/assets/js/highlight.min.js" type="text/javascript"></script>
<script type="text/javascript" src="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.js"></script>
<script src="//tensorflow.juejin.im/assets/js/main.js" type="text/javascript"></script>
</html>
<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
<html>
<head>
    <meta http-equiv="Content-Type" content="text/html;charset=UTF-8">
    <title>Losses (contrib)</title>
    <link href="//tensorflow.juejin.im/assets/css/bootstrap.min.css" rel="stylesheet">
    <link href="//tensorflow.juejin.im/assets/css/main.css" rel="stylesheet">
    <link rel="stylesheet" href="//tensorflow.juejin.im/assets/css/highlight.js.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.css" />
</head>
<body>
<!-- Header start -->
<nav class="navbar navbar-expand-lg navbar-light bg-light">
    <a class="navbar-brand" href="//tensorflow.juejin.im">TensorFlow</a>
    <button class="navbar-toggler" type="button" aria-expanded="false" aria-label="Menu"
            onclick="$('.collapse').toggle()">
        <span class="navbar-toggler-icon"></span>
    </button>

    <div class="collapse navbar-collapse">
        <ul class="navbar-nav mr-auto">
        </ul>
        <form class="form-inline my-2 my-lg-0 my-md-0">
            <input class="form-control mr-sm-2" id="search" type="search" placeholder="Search" aria-label="Search">
        </form>
    </div>
</nav>
<script>
    var head = [{'link': '//tensorflow.juejin.im/extend/index.html', 'name': '扩展', 'selected': 0}, {'link': '//tensorflow.juejin.im/install/index.html', 'name': '安装 TensorFlow', 'selected': 0}, {'link': '//tensorflow.juejin.im/deploy/index.html', 'name': '部署', 'selected': 0}, {'link': '//tensorflow.juejin.im/about/index.html', 'name': '关于 TensorFlow', 'selected': 0}, {'link': '//tensorflow.juejin.im/get_started/index.html', 'name': '开始', 'selected': 0}, {'link': '//tensorflow.juejin.im/mobile/index.html', 'name': '概述', 'selected': 0}, {'link': '//tensorflow.juejin.im/tutorials/index.html', 'name': '教程', 'selected': 0}, {'link': '//tensorflow.juejin.im/javascript/index.html', 'name': 'JavaScript', 'selected': 0}, {'link': '//tensorflow.juejin.im/performance/index.html', 'name': '性能', 'selected': 0}, {'link': '//tensorflow.juejin.im/community/index.html', 'name': '社区', 'selected': 0}, {'link': '//tensorflow.juejin.im/programmers_guide/index.html', 'name': '开发者指南', 'selected': 0}]
</script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-92630037-8"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-92630037-8');
</script>

<!-- Header end -->

<!-- Content start-->
<div class="container-fluid">
    <div class="row">
        
        <main role="main" class="col-12 col-md-9 col-xl-8 py-md-3 pl-md-5 bd-content">
            <h1 id="toc-0">Losses (contrib)</h1>
<h2 id="toc-1">Deprecated</h2>
<p><a href="https://www.tensorflow.org/api_docs/python/tf/losses"><code>tf.losses</code></a></p>
<h2 id="toc-2">Loss operations for use in neural networks.</h2>
<p>Note: By default, all the losses are collected into the <code>GraphKeys.LOSSES</code><br>
collection.</p>
<p>All of the loss functions take a pair of predictions and ground truth labels,<br>
from which the loss is computed. It is assumed that the shape of both these<br>
tensors is of the form [batch_size, d1, ... dN] where <code>batch_size</code> is the number<br>
of samples in the batch and <code>d1</code> ... <code>dN</code> are the remaining dimensions.</p>
<p>It is common, when training with multiple loss functions, to adjust the relative<br>
strengths of individual losses. This is performed by rescaling the losses via<br>
a <code>weight</code> parameter passed to the loss functions. For example, if we were<br>
training with both log_loss and mean_squared_error, and we wished that the<br>
log_loss penalty be twice as severe as the mean_squared_error, we would<br>
implement this as:</p>
<pre><code class="lang-python">  # Explicitly set the weight.
  tf.contrib.losses.log(predictions, labels, weight=2.0)

  # Uses default weight of 1.0
  tf.contrib.losses.mean_squared_error(predictions, labels)

  # All the losses are collected into the `GraphKeys.LOSSES` collection.
  losses = tf.get_collection(tf.GraphKeys.LOSSES)
</code></pre>
<p>While specifying a scalar loss rescales the loss over the entire batch,<br>
we sometimes want to rescale the loss per batch sample. For example, if we have<br>
certain examples that matter more to us to get correctly, we might want to have<br>
a higher loss that other samples whose mistakes matter less. In this case, we<br>
can provide a weight vector of length <code>batch_size</code> which results in the loss<br>
for each sample in the batch being scaled by the corresponding weight element.<br>
For example, consider the case of a classification problem where we want to<br>
maximize our accuracy but we especially interested in obtaining high accuracy<br>
for a specific class:</p>
<pre><code class="lang-python">  inputs, labels = LoadData(batch_size=3)
  logits = MyModelPredictions(inputs)

  # Ensures that the loss for examples whose ground truth class is `3` is 5x
  # higher than the loss for all other examples.
  weight = tf.multiply(4, tf.cast(tf.equal(labels, 3), tf.float32)) + 1

  onehot_labels = tf.one_hot(labels, num_classes=5)
  tf.contrib.losses.softmax_cross_entropy(logits, onehot_labels, weight=weight)
</code></pre>
<p>Finally, in certain cases, we may want to specify a different loss for every<br>
single measurable value. For example, if we are performing per-pixel depth<br>
prediction, or per-pixel denoising, a single batch sample has P values where P<br>
is the number of pixels in the image. For many losses, the number of measurable<br>
values matches the number of elements in the predictions and labels tensors.<br>
For others, such as softmax_cross_entropy and cosine_distance, the<br>
loss functions reduces the dimensions of the inputs to produces a tensor of<br>
losses for each measurable value. For example, softmax_cross_entropy takes as<br>
input predictions and labels of dimension [batch_size, num_classes] but the<br>
number of measurable values is [batch_size]. Consequently, when passing a weight<br>
tensor to specify a different loss for every measurable value, the dimension of<br>
the tensor will depend on the loss being used.</p>
<p>For a concrete example, consider the case of per-pixel depth prediction where<br>
certain ground truth depth values are missing (due to sensor noise in the<br>
capture process). In this case, we want to assign zero weight to losses for<br>
these predictions.</p>
<pre><code class="lang-python">  # &#39;depths&#39; that are missing have a value of 0:
  images, depths = LoadData(...)
  predictions = MyModelPredictions(images)

  weight = tf.cast(tf.greater(depths, 0), tf.float32)
  loss  = tf.contrib.losses.mean_squared_error(predictions, depths, weight)
</code></pre>
<p>Note that when using weights for the losses, the final average is computed<br>
by rescaling the losses by the weights and then dividing by the total number of<br>
non-zero samples. For an arbitrary set of weights, this may not necessarily<br>
produce a weighted average. Instead, it simply and transparently rescales the<br>
per-element losses before averaging over the number of observations. For example<br>
if the losses computed by the loss function is an array [4, 1, 2, 3] and the<br>
weights are an array [1, 0.5, 3, 9], then the average loss is:</p>
<pre><code class="lang-python">  (4*1 + 1*0.5 + 2*3 + 3*9) / 4
</code></pre>
<p>However, with a single loss function and an arbitrary set of weights, one can<br>
still easily create a loss function such that the resulting loss is a<br>
weighted average over the individual prediction errors:</p>
<pre><code class="lang-python">  images, labels = LoadData(...)
  predictions = MyModelPredictions(images)

  weight = MyComplicatedWeightingFunction(labels)
  weight = tf.div(weight, tf.size(weight))
  loss = tf.contrib.losses.mean_squared_error(predictions, depths, weight)
</code></pre>
<ul>
<li><a href="https://www.tensorflow.org/api_docs/python/tf/contrib/losses/absolute_difference"><code>tf.contrib.losses.absolute_difference</code></a></li>
<li><a href="https://www.tensorflow.org/api_docs/python/tf/contrib/losses/add_loss"><code>tf.contrib.losses.add_loss</code></a></li>
<li><a href="https://www.tensorflow.org/api_docs/python/tf/contrib/losses/hinge_loss"><code>tf.contrib.losses.hinge_loss</code></a></li>
<li><a href="https://www.tensorflow.org/api_docs/python/tf/contrib/losses/compute_weighted_loss"><code>tf.contrib.losses.compute_weighted_loss</code></a></li>
<li><a href="https://www.tensorflow.org/api_docs/python/tf/contrib/losses/cosine_distance"><code>tf.contrib.losses.cosine_distance</code></a></li>
<li><a href="https://www.tensorflow.org/api_docs/python/tf/contrib/losses/get_losses"><code>tf.contrib.losses.get_losses</code></a></li>
<li><a href="https://www.tensorflow.org/api_docs/python/tf/contrib/losses/get_regularization_losses"><code>tf.contrib.losses.get_regularization_losses</code></a></li>
<li><a href="https://www.tensorflow.org/api_docs/python/tf/contrib/losses/get_total_loss"><code>tf.contrib.losses.get_total_loss</code></a></li>
<li><a href="https://www.tensorflow.org/api_docs/python/tf/contrib/losses/log_loss"><code>tf.contrib.losses.log_loss</code></a></li>
<li><a href="https://www.tensorflow.org/api_docs/python/tf/contrib/losses/mean_pairwise_squared_error"><code>tf.contrib.losses.mean_pairwise_squared_error</code></a></li>
<li><a href="https://www.tensorflow.org/api_docs/python/tf/contrib/losses/mean_squared_error"><code>tf.contrib.losses.mean_squared_error</code></a></li>
<li><a href="https://www.tensorflow.org/api_docs/python/tf/contrib/losses/sigmoid_cross_entropy"><code>tf.contrib.losses.sigmoid_cross_entropy</code></a></li>
<li><a href="https://www.tensorflow.org/api_docs/python/tf/contrib/losses/softmax_cross_entropy"><code>tf.contrib.losses.softmax_cross_entropy</code></a></li>
<li><a href="https://www.tensorflow.org/api_docs/python/tf/contrib/losses/sparse_softmax_cross_entropy"><code>tf.contrib.losses.sparse_softmax_cross_entropy</code></a></li>
</ul>

        </main>
        <div class="d-none d-xl-block col-xl-2 bd-toc">
        <ul id="table-of-content">
<li><a href="#toc-0">Losses (contrib)</a><ul>
<li><a href="#toc-1">Deprecated</a></li>
<li><a href="#toc-2">Loss operations for use in neural networks.</a></li>
</ul>
</li>
</ul>

        </div>
    </div>
</div>
<!-- Content end-->

<!-- Footer start -->
<footer class="footer">
    <div class="container">
        <div>如果您发现本页面存在错误或可以改进，请<a href="https://github.com/xitu/tensorflow-docs/blob/zh-hans/api_guides/python/contrib.losses.md" target="_blank">点击此处</a>帮助我们改进。本页贡献者：<span id="contributors"></span></div>
        <hr/>
        <div class="text-center official-links">
            <a href="https://www.tensorflow.org"><img
                    src="https://www.tensorflow.org/_static/b1fb9a8564/images/tensorflow/lockup.png" height="20"/></a>
            <a href="https://github.com/xitu/tensorflow-docs"><img
                    src="https://assets-cdn.github.com/images/modules/logos_page/GitHub-Logo.png" height="20"></a>
            <a href="https://juejin.im"><img src="//tensorflow.juejin.im/assets/imgs/logo_app_white.png" height="20"/></a>
        </div>
    </div>
</footer>
<script>
    var contributors = [{'leviding': 'https://avatars3.githubusercontent.com/u/26959437?v=4'}]
</script>
<!-- Footer end -->
</body>
<script src="//tensorflow.juejin.im/assets/js/jquery.slim.min.js" type="text/javascript"></script>
<script src="//tensorflow.juejin.im/assets/js/highlight.min.js" type="text/javascript"></script>
<script type="text/javascript" src="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.js"></script>
<script src="//tensorflow.juejin.im/assets/js/main.js" type="text/javascript"></script>
</html>